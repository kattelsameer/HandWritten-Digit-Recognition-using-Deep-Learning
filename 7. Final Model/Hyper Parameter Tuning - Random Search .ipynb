{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Libraries for importing data from binary file\n",
    "import os.path #for accessing the file path\n",
    "import struct  #for unpacking the binary data\n",
    "\n",
    "import time    #for calculating time\n",
    "import math    #for using floor in creating minibatches\n",
    "\n",
    "\n",
    "#core packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Ellipse\n",
    "\n",
    "\n",
    "#custom module\n",
    "from dataPrep import load_dataset, load_sample_dataset\n",
    "from dataPrep import prep_dataset, rand_mini_batches\n",
    "\n",
    "from finalModelUtils import *\n",
    "from ffnn import *\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading complete dataset\n",
    "train_x_orig, train_y_orig, dev_x_orig,dev_y_orig,test_x_orig,test_y_orig = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size : 25%\n",
      "\n",
      "Data\t\t\t Complete Dataset\t Sample Dataset\t\n",
      "================================================================\n",
      "Training Set Images:\t(60000, 28, 28)\t\t(15000, 28, 28)\n",
      "Training Set Labels:\t(60000, 1)\t\t(15000, 1)\n",
      "Training Set Images:\t(5000, 28, 28)\t\t(1250, 28, 28)\n",
      "Training Set Labels:\t(5000, 1)\t\t(1250, 1)\n",
      "Test Set Images:\t(5000, 28, 28)\t\t(1250, 28, 28)\n",
      "Test Set Labels:\t(5000, 1)\t\t(1250, 1)\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "#loading Sample dataset\n",
    "sample_size = 25\n",
    "train_x_sample, train_y_sample, dev_x_sample, dev_y_sample, test_x_sample, test_y_sample = load_sample_dataset(sample_size)\n",
    "\n",
    "print(\"Sample Size : %d%%\\n\"%(sample_size))\n",
    "print(\"Data\\t\\t\\t\",\"Complete Dataset\\t\",\"Sample Dataset\\t\")\n",
    "print(\"================================================================\")\n",
    "print(\"Training Set Images:\\t\"+ str(train_x_orig.shape)+\"\\t\\t\"+ str(train_x_sample.shape))\n",
    "print(\"Training Set Labels:\\t\"+ str(train_y_orig.shape)+\"\\t\\t\"+ str(train_y_sample.shape))\n",
    "print(\"Training Set Images:\\t\"+ str(dev_x_orig.shape)+\"\\t\\t\"+ str(dev_x_sample.shape))\n",
    "print(\"Training Set Labels:\\t\"+ str(dev_y_orig.shape)+\"\\t\\t\"+ str(dev_y_sample.shape))\n",
    "print(\"Test Set Images:\\t\"+str(test_x_orig.shape)+\"\\t\\t\"+ str(test_x_sample.shape))\n",
    "print(\"Test Set Labels:\\t\"+str(test_y_orig.shape)+\"\\t\\t\"+ str(test_y_sample.shape))\n",
    "print(\"================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\t\t Before Processing\t After Processing\n",
      "=================================================================\n",
      "Training Set Images:\t(15000, 28, 28)\t\t(784, 15000)\n",
      "Training Set Labels:\t(15000, 1)\t\t(10, 15000)\n",
      "Dev Set Images:\t\t(1250, 28, 28)\t\t(784, 1250)\n",
      "Dev Set Labels:\t\t(1250, 1)\t\t(10, 1250)\n",
      "Test Set Images:\t(1250, 28, 28)\t\t(784, 1250)\n",
      "Test Set Labels:\t(1250, 1)\t\t(10, 1250)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Preparing the Dataset (Flattening and Normalizing)\n",
    "train_x_norm,train_y_encoded, dev_x_norm,dev_y_encoded, test_x_norm, test_y_encoded = prep_dataset(train_x_sample, train_y_sample, dev_x_sample, dev_y_sample, test_x_sample, test_y_sample)\n",
    "print(\"Data\\t\\t\\t\",\"Before Processing\\t\",\"After Processing\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(train_x_sample.shape)+\"\\t\\t\"+ str(train_x_norm.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(train_y_sample.shape)+\"\\t\\t\"+ str(train_y_encoded.shape))\n",
    "print(\"Dev Set Images:\\t\\t\" + str(dev_x_sample.shape)+\"\\t\\t\"+ str(dev_x_norm.shape))\n",
    "print(\"Dev Set Labels:\\t\\t\" + str(dev_y_sample.shape)+\"\\t\\t\"+ str(dev_y_encoded.shape))\n",
    "print(\"Test Set Images:\\t\" + str(test_x_sample.shape)+\"\\t\\t\"+ str(test_x_norm.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(test_y_sample.shape)+\"\\t\\t\"+ str(test_y_encoded.shape))\n",
    "print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dim = init_layers(train_x_norm, train_y_encoded, hidden_layers = [800,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParams = init_hyperParams(alpha = 0.0001, num_epoch = 5, mini_batch_size = 512,lambd = 0.7,keep_probs = [0.9,0.8,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = train(train_x_norm, train_y_encoded,dev_x_norm, dev_y_encoded,layers_dim, hyperParams, initialization = \"he\", optimizer = 'adam',regularizer = 'l2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = []\n",
    "for i in range(100):\n",
    "    r = np.random.uniform(-5, -1)\n",
    "    p = 10 ** r\n",
    "#     print(r,p)\n",
    "    sam.append(p)\n",
    "\n",
    "\n",
    "plt.hist(sam,bins = 10)\n",
    "    \n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperParams(hParam_type, rng, sample_size):\n",
    "\n",
    "    sample = []\n",
    "    \n",
    "    lower_range = rng[0]\n",
    "    higher_range = rng[1]\n",
    "    \n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        if hParam_type == \"learning_rate\":\n",
    "            r = np.random.uniform(lower_range,higher_range)\n",
    "            p = 10 ** r\n",
    "            sample.append(p)\n",
    "        elif hParam_type == \"minibatch_size\":\n",
    "            s = np.random.randint(low = lower_range, high = higher_range)\n",
    "            sample.append(s)\n",
    "        else:\n",
    "            raise ValueError(\"Sampling of only learning rate and minibatch size is possible for now\")\n",
    "            \n",
    "    assert(len(sample) == sample_size)\n",
    "    \n",
    "    return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leaning_rate_ = sample_hyperParams(hParam_type =\"learning_rate\",rng = [-4,-1],sample_size = 200)\n",
    "minibatch_size_ = sample_hyperParams(hParam_type =\"minibatch_size\",rng = [16,1024],sample_size = 200)\n",
    "\n",
    "# plt.style.use('seaborn')\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 2, figsize=(20,15))\n",
    "ax[0,0].set_ylim(top = 1.2 * 10e-2, bottom = 0.8 * 10e-5)\n",
    "ax[0,0].scatter(minibatch_size_,leaning_rate_, color = \"gray\")\n",
    "ax[0,0].set_yscale('log')\n",
    "# ax[0,0].grid()\n",
    "rec = Rectangle((128,0.0001), 800-128 , 0.006-0.0001, fill=False, edgecolor=\"green\")\n",
    "ax[0,0].add_patch(rec)\n",
    "\n",
    "# Add labels to the plot\n",
    "style = dict(size=10, color='blue', alpha = 0.5)\n",
    "ax[0,0].text(128, 0.006+0.006*0.1, \"New Search Range \", ha='left', **style)\n",
    "\n",
    "c = Ellipse((356,0.0005),width = 0.1 * 356 ,  height =0.25 * 0.0005, edgecolor='crimson', fill = False, alpha=0.5)\n",
    "ax[0,0].add_patch(c)\n",
    "ax[0,0].text(356 + 25, 0.0005 , \"Best Choice \", ha='left', **style)\n",
    "\n",
    "\n",
    "num_mini_batch = ax[1,0].hist(minibatch_size_, bins = 20)\n",
    "\n",
    "num_alpha = ax[1,1].hist(leaning_rate_, bins = 100)\n",
    "ax[1,1].set_xscale('log') #changing the scale to log scale to plot learning rate which is in log scale\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_search_space(score, threshold, samples, summary = True):\n",
    "    learning_rate = samples[\"learning_rate\"]\n",
    "    minibatch_size = samples[\"minibatch_size\"]\n",
    "    \n",
    "    good_lrs = []\n",
    "    good_mbs = []\n",
    "    good_scs = []\n",
    "    \n",
    "    #getting the score above the threshold and along with their corresponding hyper parameters\n",
    "    for ind, val in enumerate(score):\n",
    "        if val > threshold:\n",
    "            good_lrs.append(learning_rate[ind])\n",
    "            good_mbs.append(minibatch_size[ind])\n",
    "            good_scs.append(val)\n",
    "            \n",
    "    if len(good_scs) != 0:  \n",
    "        \n",
    "        if summary == True:\n",
    "            print(\"+================+===============+================+\")\n",
    "            print(\"| Validation Acc | Learning Rate | Minibatch Size |\")\n",
    "            print(\"+================+===============+================+\")\n",
    "\n",
    "            for ind,sc in enumerate(good_scs):\n",
    "                print(\"| %.5f\\t | %.5f\\t | %d\\t\\t  |\"%(sc, good_lrs[ind], good_mbs[ind]))\n",
    "\n",
    "            print(\"+================+===============+================+\")\n",
    "        \n",
    "        #calculating the new search range in log form after expanding the learning rate space by 10 %\n",
    "        lr_rng_new = [np.log10(0.9 * min(good_lrs) ), np.log10(1.1 * max(good_lrs))] \n",
    "\n",
    "        #calculating the new search range for minibatch size by expanding the search space by 10%\n",
    "        mbs_rng_new = [0.9 * min(good_mbs), 1.1 * max(good_mbs)] \n",
    "        \n",
    "    else:\n",
    "        print(\"No accuracy or only one accuracy beyond threshold was obtained, so range was calculated based on the best score\")\n",
    "        max_lr = learning_rate[np.argmax(score)] \n",
    "        \n",
    "        #calculating the new search range in log form  from the learning rate of best score, expanding by 50 % in each direction\n",
    "        lr_rng_new = [np.log10(0.5 * max_lr), np.log10(1.5 * max_lr)] #calculating the range in log scale\n",
    "        \n",
    "        max_mbs = minibatch_size[np.argmax(score)]\n",
    "        \n",
    "        #calculating the new search range from the minibatch size of best score, expanding by 25 % in each direction\n",
    "        mbs_rng_new = [0.75 * max_mbs, 1.25 * max_mbs] #calculaing the range\n",
    "        \n",
    "        \n",
    "        \n",
    "    #best hyper parameter combinations\n",
    "    best_comb = [np.max(score),learning_rate[np.argmax(score)],minibatch_size[np.argmax(score)]]\n",
    "\n",
    "    if summary == True:\n",
    "       \n",
    "        print(\"New Search Space for Learning Rate: [%.6f,%.6f]\"%(10 ** lr_rng_new[0], 10 ** lr_rng_new[1]))\n",
    "        print(\"New Search Space for Minibatch Size: [%d,%d]\"%(mbs_rng_new[0], mbs_rng_new[1]))\n",
    "        print(\"Best Score: %.6f \"%(best_comb[0]))\n",
    "        print(\"Best Hyper Params:\\n Learning Rate: %.6f\\n Minibatch Size: %d\"%(best_comb[1], best_comb[2]))\n",
    "  \n",
    "    \n",
    "    return lr_rng_new, mbs_rng_new, best_comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = np.random.uniform(0,1,100)\n",
    "# print(sc)\n",
    "thres = 0.90\n",
    "\n",
    "lr = []\n",
    "for i in range(100):\n",
    "    r = np.random.uniform(-5, -1)\n",
    "    p = 10 ** r\n",
    "    lr.append(p)\n",
    "    \n",
    "mbz = np.random.randint(50,2200,100)\n",
    "\n",
    "samples = {\"learning_rate\": lr,\n",
    "               \"minibatch_size\" : mbz}\n",
    "score_threshold = 0.90\n",
    "\n",
    "\n",
    "lr_rng, mbs_rng, best = calculate_new_search_space(sc,score_threshold,samples, summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_search(samples,score, lr_rng_new, mbs_rng_new, best_comb):\n",
    "    \n",
    "    learning_rate = samples[\"learning_rate\"]\n",
    "    minibatch_size = samples[\"minibatch_size\"]\n",
    "    lr_min = 10 ** lr_rng_new[0]\n",
    "    lr_max = 10 ** lr_rng_new[1]\n",
    "    \n",
    "    # plt.style.use('seaborn')\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(10,7))\n",
    "    ax.set_ylim(top = 1.2 * 10**lr_rng_new[1], bottom = 0.8 * 10**lr_rng_new[0])\n",
    "    \n",
    "    ax.scatter(minibatch_size,learning_rate, color = \"gray\",alpha=0.80)\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "    \n",
    "    rec = Rectangle((mbs_rng_new[0], lr_min), mbs_rng_new[1] - mbs_rng_new[0], lr_max - lr_min, fill=False, edgecolor=\"green\")\n",
    "    ax.add_patch(rec)\n",
    "\n",
    "    c = Ellipse((best_comb[2],best_comb[1]),width = 30,  height =0.30 * best_comb[1], edgecolor='green', fill = False, alpha=0.5)\n",
    "    ax.add_patch(c)\n",
    "    ax.scatter(best_comb[2],best_comb[1], color = \"crimson\",alpha=1)\n",
    "\n",
    "\n",
    "    # Add labels to the plot\n",
    "    style = dict(size=10, color='blue', alpha = 0.8)\n",
    "    ax.text(mbs_rng_new[0], lr_max + 0.1*lr_max, \"New Search Range \", ha='left', **style)\n",
    "    ax.text(best_comb[2] + 25, best_comb[1] , \"Best Choice \", ha='left', **style)\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+================+===============+================+\n",
      "| Validation Acc | Learning Rate | Minibatch Size |\n",
      "+================+===============+================+\n",
      "| 0.90906\t | 0.06045\t | 53\t\t  |\n",
      "| 0.91298\t | 0.03182\t | 108\t\t  |\n",
      "| 0.97337\t | 0.00440\t | 684\t\t  |\n",
      "| 0.96932\t | 0.00135\t | 887\t\t  |\n",
      "| 0.97938\t | 0.00261\t | 420\t\t  |\n",
      "| 0.98022\t | 0.00195\t | 839\t\t  |\n",
      "| 0.94058\t | 0.02877\t | 899\t\t  |\n",
      "| 0.94978\t | 0.00019\t | 508\t\t  |\n",
      "| 0.92998\t | 0.00098\t | 311\t\t  |\n",
      "| 0.96648\t | 0.00038\t | 416\t\t  |\n",
      "+================+===============+================+\n",
      "New Search Space for Learning Rate: [0.000167,0.066498]\n",
      "New Search Space for Minibatch Size: [47,988]\n",
      "Best Score: 0.980222 \n",
      "Best Hyper Params:\n",
      " Learning Rate: 0.001952\n",
      " Minibatch Size: 839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = np.random.uniform(0,1,100)\n",
    "# print(sc)\n",
    "thres = 0.90\n",
    "\n",
    "lr = []\n",
    "for i in range(100):\n",
    "    r = np.random.uniform(-4, -1)\n",
    "    p = 10 ** r\n",
    "    lr.append(p)\n",
    "    \n",
    "mbz = np.random.randint(16,1024,100)\n",
    "\n",
    "samples = {\"learning_rate\": lr,\n",
    "               \"minibatch_size\" : mbz}\n",
    "score_threshold = 0.90\n",
    "\n",
    "lr_rng, mbs_rng, best = calculate_new_search_space(sc,score_threshold,samples, summary = True)\n",
    "\n",
    "visualize_search(samples,sc, lr_rng, mbs_rng, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coarse search with 2 epoch, fine search with 5 epoch and detailed search with 10 epoch\n",
    "\n",
    "def random_search_2D(param1, param2, search_type =\"coarse\", evaluate_metric = \"accuracy\", sample_size = 100, search_summary = True, search_visualization = True):\n",
    "    \n",
    "    #accessing the input parameter types and their range\n",
    "    hParam_type1 = param1[\"hParam type\"]\n",
    "    hParam_range1 = param1[\"hParam range\"]\n",
    "    \n",
    "    hParam_type2 = param2[\"hParam type\"]\n",
    "    hParam_range2 = param2[\"hParam range\"]\n",
    "    \n",
    "    samples = {} #for storing the generated samples\n",
    "    \n",
    "    #checking the search type\n",
    "    if search_type == \"coarse\":\n",
    "        epoch_size = 2\n",
    "        score_threshold = 0.95\n",
    "    elif search_type == \"fine\":\n",
    "        epoch_size = 5\n",
    "        score_threshold = 0.97\n",
    "    elif search_type == \"detail\":\n",
    "        epoch_size = 10\n",
    "        score_threshold = 0.99\n",
    "    else:\n",
    "        raise ValueError(\"Search Type not identified. Must be 'coarse', 'fine', or 'detail'\")\n",
    "    \n",
    "    #generating Samples for two input parameters\n",
    "    samples[hParam_type1] = sample_hyperParams(hParam_type = hParam_type1, rng = hParam_range1, sample_size = sample_size)\n",
    "    samples[hParam_type2] = sample_hyperParams(hParam_type = hParam_type2,rng = hParam_range2, sample_size = sample_size)\n",
    "    \n",
    "            \n",
    "    if hParam_type1 == \"learning_rate\":\n",
    "        leaning_rate_samples =  samples[hParam_type1]\n",
    "    elif hParam_type2 == \"learning_rate\":\n",
    "        leaning_rate_samples =  samples[hParam_type2]\n",
    "    \n",
    "\n",
    "    if hParam_type2 == \"minibatch_size\":\n",
    "        minibatch_size_samples =  samples[hParam_type2]\n",
    "    elif hParam_type1 == \"minibatch_size\":\n",
    "        minibatch_size_samples =  samples[hParam_type2]\n",
    "    \n",
    "        \n",
    "    score = []\n",
    "    \n",
    "    toc = time.time()\n",
    "        \n",
    "    for i in range(sample_size):\n",
    "        print(\"\\nSample: %d/%d -- Learning Rate: %.6f | Minibatch Size: %d\"%(i+1,sample_size,leaning_rate_samples[i],minibatch_size_samples[i]))\n",
    "        print(\"==========================================================================================================\")\n",
    "        \n",
    "        hyperParams = init_hyperParams(alpha = leaning_rate_samples[i], num_epoch = epoch_size, mini_batch_size = minibatch_size_samples[i])\n",
    "        \n",
    "        parameters = train(train_x_norm, train_y_encoded, dev_x_norm, dev_y_encoded,layers_dim, hyperParams, initialization = \"he\", optimizer = 'adam', visualize = False) \n",
    "        \n",
    "        if evaluate_metric == \"accuracy\":\n",
    "            prediction_dev,dev_acc, _ = predict(dev_x_norm, dev_y_encoded,parameters)\n",
    "            score.append(dev_acc)\n",
    "\n",
    "        elif evaluate_metric == \"f1-score\": \n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Metric must be 'accuracy' or 'f1-score'\")\n",
    "        \n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    tic = time.time() # for calculating entire search time\n",
    "    hrs, mins, secs , ms = convert_time((tic - toc)*1000)\n",
    "    \n",
    "    print(\"\\n\\n*************************** Total Search Time = %dhr %dmins %dsecs %.2fms ***************************\\n\\n\"%(hrs, mins, secs, ms))\n",
    "    \n",
    "    assert(len(score) == sample_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if search_summary == True:\n",
    "        print(search_type.capitalize()+\" Search Summary: \\n\")\n",
    "    \n",
    "    lr_rng_new, mbs_rng_new, best_comb = calculate_new_search_space(score, score_threshold, samples, summary = search_summary)\n",
    "    \n",
    "    if search_visualization == True:\n",
    "#         pass\n",
    "        visualize_search(samples,score,lr_rng_new, mbs_rng_new, best_comb)\n",
    "    \n",
    "    return lr_rng_new, mbs_rng_new, best_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample: 1/100 -- Learning Rate: 0.000363 | Minibatch Size: 198\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 30.06s | loss: 0.2616 | acc: 0.9274 | Val loss: 0.2520 | Val acc: 0.9328 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 33.69s | loss: 0.1758 | acc: 0.9523 | Val loss: 0.1905 | Val acc: 0.9512 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 3secs 814.76ms ***************************\n",
      "\n",
      "Sample: 2/100 -- Learning Rate: 0.000193 | Minibatch Size: 267\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 25.99s | loss: 0.4111 | acc: 0.8939 | Val loss: 0.3816 | Val acc: 0.9072 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 25.38s | loss: 0.2729 | acc: 0.9292 | Val loss: 0.2627 | Val acc: 0.9336 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 51secs 433.02ms ***************************\n",
      "\n",
      "Sample: 3/100 -- Learning Rate: 0.011994 | Minibatch Size: 960\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.64s | loss: 0.4459 | acc: 0.8729 | Val loss: 0.4052 | Val acc: 0.8872 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.09s | loss: 0.1968 | acc: 0.9431 | Val loss: 0.2138 | Val acc: 0.9392 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 14secs 786.27ms ***************************\n",
      "\n",
      "Sample: 4/100 -- Learning Rate: 0.001523 | Minibatch Size: 910\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 8.34s | loss: 0.2980 | acc: 0.9169 | Val loss: 0.2943 | Val acc: 0.9208 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 8.42s | loss: 0.1848 | acc: 0.9477 | Val loss: 0.2008 | Val acc: 0.9464 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 16secs 811.56ms ***************************\n",
      "\n",
      "Sample: 5/100 -- Learning Rate: 0.009849 | Minibatch Size: 113\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 55.74s | loss: 0.1828 | acc: 0.9421 | Val loss: 0.2261 | Val acc: 0.9256 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 55.51s | loss: 0.1065 | acc: 0.9684 | Val loss: 0.1558 | Val acc: 0.9600 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 51secs 340.91ms ***************************\n",
      "\n",
      "Sample: 6/100 -- Learning Rate: 0.037682 | Minibatch Size: 815\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 8.76s | loss: 0.4886 | acc: 0.8691 | Val loss: 0.4956 | Val acc: 0.8776 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 8.65s | loss: 0.2681 | acc: 0.9202 | Val loss: 0.2661 | Val acc: 0.9280 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 17secs 460.45ms ***************************\n",
      "\n",
      "Sample: 7/100 -- Learning Rate: 0.047092 | Minibatch Size: 1015\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.03s | loss: 1.0315 | acc: 0.6469 | Val loss: 0.9658 | Val acc: 0.6624 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.05s | loss: 0.5665 | acc: 0.8119 | Val loss: 0.5291 | Val acc: 0.8304 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 14secs 133.43ms ***************************\n",
      "\n",
      "Sample: 8/100 -- Learning Rate: 0.006436 | Minibatch Size: 982\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.79s | loss: 0.3322 | acc: 0.9052 | Val loss: 0.3012 | Val acc: 0.9160 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.71s | loss: 0.1659 | acc: 0.9521 | Val loss: 0.1854 | Val acc: 0.9472 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 15secs 565.08ms ***************************\n",
      "\n",
      "Sample: 9/100 -- Learning Rate: 0.000569 | Minibatch Size: 772\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 9.97s | loss: 0.3873 | acc: 0.8919 | Val loss: 0.3512 | Val acc: 0.9032 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.78s | loss: 0.2533 | acc: 0.9277 | Val loss: 0.2507 | Val acc: 0.9320 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 19secs 805.32ms ***************************\n",
      "\n",
      "Sample: 10/100 -- Learning Rate: 0.013092 | Minibatch Size: 369\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 17.71s | loss: 0.1769 | acc: 0.9461 | Val loss: 0.1905 | Val acc: 0.9472 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 17.62s | loss: 0.1025 | acc: 0.9669 | Val loss: 0.1445 | Val acc: 0.9536 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 35secs 402.96ms ***************************\n",
      "\n",
      "Sample: 11/100 -- Learning Rate: 0.003642 | Minibatch Size: 470\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 14.83s | loss: 0.1821 | acc: 0.9454 | Val loss: 0.2010 | Val acc: 0.9456 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 14.91s | loss: 0.1076 | acc: 0.9680 | Val loss: 0.1462 | Val acc: 0.9576 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 29secs 796.52ms ***************************\n",
      "\n",
      "Sample: 12/100 -- Learning Rate: 0.000222 | Minibatch Size: 890\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 8.59s | loss: 0.9920 | acc: 0.8207 | Val loss: 0.9639 | Val acc: 0.8344 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 8.59s | loss: 0.4886 | acc: 0.8819 | Val loss: 0.4515 | Val acc: 0.8968 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 17secs 239.33ms ***************************\n",
      "\n",
      "Sample: 13/100 -- Learning Rate: 0.067088 | Minibatch Size: 976\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.35s | loss: 1.3590 | acc: 0.5541 | Val loss: 1.3473 | Val acc: 0.5736 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.31s | loss: 0.9308 | acc: 0.6467 | Val loss: 0.9222 | Val acc: 0.6376 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 14secs 717.49ms ***************************\n",
      "\n",
      "Sample: 14/100 -- Learning Rate: 0.000614 | Minibatch Size: 105\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 63.73s | loss: 0.1883 | acc: 0.9469 | Val loss: 0.2116 | Val acc: 0.9432 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 64.55s | loss: 0.1003 | acc: 0.9727 | Val loss: 0.1443 | Val acc: 0.9640 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 8secs 375.74ms ***************************\n",
      "\n",
      "Sample: 15/100 -- Learning Rate: 0.039133 | Minibatch Size: 174\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 36.17s | loss: 0.3509 | acc: 0.9094 | Val loss: 0.3639 | Val acc: 0.9048 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 35.83s | loss: 0.2469 | acc: 0.9266 | Val loss: 0.2969 | Val acc: 0.9232 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 12secs 84.66ms ***************************\n",
      "\n",
      "Sample: 16/100 -- Learning Rate: 0.003813 | Minibatch Size: 596\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.28s | loss: 0.2048 | acc: 0.9372 | Val loss: 0.2162 | Val acc: 0.9456 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.18s | loss: 0.1192 | acc: 0.9647 | Val loss: 0.1412 | Val acc: 0.9600 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 24secs 526.17ms ***************************\n",
      "\n",
      "Sample: 17/100 -- Learning Rate: 0.000335 | Minibatch Size: 412\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 17.24s | loss: 0.3668 | acc: 0.8984 | Val loss: 0.3403 | Val acc: 0.9080 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 17.02s | loss: 0.2446 | acc: 0.9353 | Val loss: 0.2390 | Val acc: 0.9384 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 34secs 313.53ms ***************************\n",
      "\n",
      "Sample: 18/100 -- Learning Rate: 0.000161 | Minibatch Size: 506\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 14.32s | loss: 0.8038 | acc: 0.8402 | Val loss: 0.7701 | Val acc: 0.8600 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 14.12s | loss: 0.4082 | acc: 0.8982 | Val loss: 0.3796 | Val acc: 0.9096 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 28secs 497.46ms ***************************\n",
      "\n",
      "Sample: 19/100 -- Learning Rate: 0.047447 | Minibatch Size: 72\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 84.51s | loss: 0.4554 | acc: 0.8787 | Val loss: 0.5024 | Val acc: 0.8728 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 84.46s | loss: 0.3863 | acc: 0.8924 | Val loss: 0.4313 | Val acc: 0.8840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 49secs 78.27ms ***************************\n",
      "\n",
      "Sample: 20/100 -- Learning Rate: 0.072727 | Minibatch Size: 546\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.52s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.52s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 101.75ms ***************************\n",
      "\n",
      "Sample: 21/100 -- Learning Rate: 0.001120 | Minibatch Size: 572\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.86s | loss: 0.2713 | acc: 0.9227 | Val loss: 0.2691 | Val acc: 0.9264 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.81s | loss: 0.1778 | acc: 0.9491 | Val loss: 0.1966 | Val acc: 0.9496 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 730.55ms ***************************\n",
      "\n",
      "Sample: 22/100 -- Learning Rate: 0.034488 | Minibatch Size: 747\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 9.47s | loss: 0.5607 | acc: 0.8291 | Val loss: 0.5172 | Val acc: 0.8472 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.38s | loss: 0.2885 | acc: 0.9107 | Val loss: 0.2871 | Val acc: 0.9152 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 18secs 905.34ms ***************************\n",
      "\n",
      "Sample: 23/100 -- Learning Rate: 0.000365 | Minibatch Size: 687\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 10.77s | loss: 0.4965 | acc: 0.8739 | Val loss: 0.4569 | Val acc: 0.8896 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.31s | loss: 0.2919 | acc: 0.9197 | Val loss: 0.2777 | Val acc: 0.9280 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 140.15ms ***************************\n",
      "\n",
      "Sample: 24/100 -- Learning Rate: 0.001381 | Minibatch Size: 801\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 10.89s | loss: 0.2943 | acc: 0.9172 | Val loss: 0.2857 | Val acc: 0.9232 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.90s | loss: 0.1746 | acc: 0.9503 | Val loss: 0.1915 | Val acc: 0.9496 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 20secs 849.99ms ***************************\n",
      "\n",
      "Sample: 25/100 -- Learning Rate: 0.003813 | Minibatch Size: 147\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 51.37s | loss: 0.1676 | acc: 0.9465 | Val loss: 0.1920 | Val acc: 0.9416 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 51.00s | loss: 0.0857 | acc: 0.9736 | Val loss: 0.1202 | Val acc: 0.9664 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 42secs 453.94ms ***************************\n",
      "\n",
      "Sample: 26/100 -- Learning Rate: 0.056603 | Minibatch Size: 513\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 14.33s | loss: 0.6381 | acc: 0.8127 | Val loss: 0.6454 | Val acc: 0.8232 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 13.38s | loss: 0.4441 | acc: 0.8760 | Val loss: 0.5111 | Val acc: 0.8680 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 27secs 774.49ms ***************************\n",
      "\n",
      "Sample: 27/100 -- Learning Rate: 0.000451 | Minibatch Size: 51\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 150.67s | loss: 0.1814 | acc: 0.9487 | Val loss: 0.2136 | Val acc: 0.9424 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 180.88s | loss: 0.0928 | acc: 0.9748 | Val loss: 0.1465 | Val acc: 0.9632 \n",
      "\n",
      "*************************** Total Training Time = 0hr 5mins 31secs 680.58ms ***************************\n",
      "\n",
      "Sample: 28/100 -- Learning Rate: 0.000650 | Minibatch Size: 937\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.83s | loss: 0.4184 | acc: 0.8749 | Val loss: 0.3763 | Val acc: 0.8944 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.26s | loss: 0.2862 | acc: 0.9187 | Val loss: 0.2755 | Val acc: 0.9256 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 150.92ms ***************************\n",
      "\n",
      "Sample: 29/100 -- Learning Rate: 0.018846 | Minibatch Size: 270\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 36.90s | loss: 0.1869 | acc: 0.9418 | Val loss: 0.1950 | Val acc: 0.9432 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 32.78s | loss: 0.1254 | acc: 0.9619 | Val loss: 0.1883 | Val acc: 0.9440 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 9secs 778.25ms ***************************\n",
      "\n",
      "Sample: 30/100 -- Learning Rate: 0.006482 | Minibatch Size: 671\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.83s | loss: 0.2883 | acc: 0.9122 | Val loss: 0.2873 | Val acc: 0.9160 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.91s | loss: 0.1328 | acc: 0.9607 | Val loss: 0.1547 | Val acc: 0.9552 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 24secs 802.83ms ***************************\n",
      "\n",
      "Sample: 31/100 -- Learning Rate: 0.000347 | Minibatch Size: 422\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 22.45s | loss: 0.3630 | acc: 0.8994 | Val loss: 0.3376 | Val acc: 0.9088 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 21.77s | loss: 0.2430 | acc: 0.9357 | Val loss: 0.2377 | Val acc: 0.9376 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 44secs 286.54ms ***************************\n",
      "\n",
      "Sample: 32/100 -- Learning Rate: 0.001299 | Minibatch Size: 859\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.81s | loss: 0.3034 | acc: 0.9154 | Val loss: 0.2918 | Val acc: 0.9192 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.86s | loss: 0.1880 | acc: 0.9466 | Val loss: 0.2003 | Val acc: 0.9424 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 749.14ms ***************************\n",
      "\n",
      "Sample: 33/100 -- Learning Rate: 0.013376 | Minibatch Size: 224\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 34.77s | loss: 0.1623 | acc: 0.9509 | Val loss: 0.1873 | Val acc: 0.9416 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 34.58s | loss: 0.1138 | acc: 0.9635 | Val loss: 0.1815 | Val acc: 0.9464 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 9secs 425.52ms ***************************\n",
      "\n",
      "Sample: 34/100 -- Learning Rate: 0.001178 | Minibatch Size: 756\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.89s | loss: 0.2980 | acc: 0.9146 | Val loss: 0.2847 | Val acc: 0.9272 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.70s | loss: 0.1849 | acc: 0.9481 | Val loss: 0.1976 | Val acc: 0.9464 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 656.36ms ***************************\n",
      "\n",
      "Sample: 35/100 -- Learning Rate: 0.000363 | Minibatch Size: 737\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.22s | loss: 0.5164 | acc: 0.8701 | Val loss: 0.4773 | Val acc: 0.8864 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 13.23s | loss: 0.3007 | acc: 0.9168 | Val loss: 0.2845 | Val acc: 0.9240 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 527.71ms ***************************\n",
      "\n",
      "Sample: 36/100 -- Learning Rate: 0.000131 | Minibatch Size: 56\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 151.62s | loss: 0.2890 | acc: 0.9233 | Val loss: 0.2823 | Val acc: 0.9248 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 140.95s | loss: 0.1921 | acc: 0.9504 | Val loss: 0.2089 | Val acc: 0.9480 \n",
      "\n",
      "*************************** Total Training Time = 0hr 4mins 52secs 704.82ms ***************************\n",
      "\n",
      "Sample: 37/100 -- Learning Rate: 0.000528 | Minibatch Size: 24\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 356.58s | loss: 0.1494 | acc: 0.9571 | Val loss: 0.1802 | Val acc: 0.9520 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 333.42s | loss: 0.0669 | acc: 0.9815 | Val loss: 0.1222 | Val acc: 0.9672 \n",
      "\n",
      "*************************** Total Training Time = 0hr 11mins 30secs 247.19ms ***************************\n",
      "\n",
      "Sample: 38/100 -- Learning Rate: 0.000692 | Minibatch Size: 763\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 9.56s | loss: 0.3546 | acc: 0.8971 | Val loss: 0.3268 | Val acc: 0.9112 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.34s | loss: 0.2341 | acc: 0.9336 | Val loss: 0.2365 | Val acc: 0.9344 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 18secs 951.98ms ***************************\n",
      "\n",
      "Sample: 39/100 -- Learning Rate: 0.015572 | Minibatch Size: 859\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.86s | loss: 0.3699 | acc: 0.8938 | Val loss: 0.3655 | Val acc: 0.8904 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.82s | loss: 0.1716 | acc: 0.9493 | Val loss: 0.1890 | Val acc: 0.9464 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 15secs 737.03ms ***************************\n",
      "\n",
      "Sample: 40/100 -- Learning Rate: 0.003648 | Minibatch Size: 340\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 19.77s | loss: 0.1738 | acc: 0.9491 | Val loss: 0.1878 | Val acc: 0.9464 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 19.75s | loss: 0.0833 | acc: 0.9759 | Val loss: 0.1214 | Val acc: 0.9664 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 39secs 583.69ms ***************************\n",
      "\n",
      "Sample: 41/100 -- Learning Rate: 0.000180 | Minibatch Size: 36\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 214.47s | loss: 0.2304 | acc: 0.9364 | Val loss: 0.2425 | Val acc: 0.9344 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 224.10s | loss: 0.1379 | acc: 0.9645 | Val loss: 0.1745 | Val acc: 0.9560 \n",
      "\n",
      "*************************** Total Training Time = 0hr 7mins 18secs 740.94ms ***************************\n",
      "\n",
      "Sample: 42/100 -- Learning Rate: 0.000525 | Minibatch Size: 717\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 14.30s | loss: 0.3964 | acc: 0.8870 | Val loss: 0.3595 | Val acc: 0.8984 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 15.47s | loss: 0.2562 | acc: 0.9281 | Val loss: 0.2517 | Val acc: 0.9328 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 29secs 852.84ms ***************************\n",
      "\n",
      "Sample: 43/100 -- Learning Rate: 0.000620 | Minibatch Size: 937\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.22s | loss: 0.4303 | acc: 0.8717 | Val loss: 0.3878 | Val acc: 0.8904 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.80s | loss: 0.2939 | acc: 0.9156 | Val loss: 0.2813 | Val acc: 0.9232 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 97.50ms ***************************\n",
      "\n",
      "Sample: 44/100 -- Learning Rate: 0.000437 | Minibatch Size: 954\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.55s | loss: 0.5594 | acc: 0.8625 | Val loss: 0.5202 | Val acc: 0.8816 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.97s | loss: 0.3179 | acc: 0.9097 | Val loss: 0.2995 | Val acc: 0.9184 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 592.74ms ***************************\n",
      "\n",
      "Sample: 45/100 -- Learning Rate: 0.000546 | Minibatch Size: 459\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 24.60s | loss: 0.3059 | acc: 0.9128 | Val loss: 0.2872 | Val acc: 0.9240 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 22.44s | loss: 0.2108 | acc: 0.9421 | Val loss: 0.2166 | Val acc: 0.9440 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 47secs 127.13ms ***************************\n",
      "\n",
      "Sample: 46/100 -- Learning Rate: 0.000128 | Minibatch Size: 197\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 48.62s | loss: 0.4653 | acc: 0.8873 | Val loss: 0.4327 | Val acc: 0.8992 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 46.32s | loss: 0.2971 | acc: 0.9241 | Val loss: 0.2833 | Val acc: 0.9304 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 35secs 33.79ms ***************************\n",
      "\n",
      "Sample: 47/100 -- Learning Rate: 0.000509 | Minibatch Size: 212\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 43.78s | loss: 0.2432 | acc: 0.9313 | Val loss: 0.2509 | Val acc: 0.9288 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 44.62s | loss: 0.1529 | acc: 0.9596 | Val loss: 0.1825 | Val acc: 0.9528 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 28secs 497.79ms ***************************\n",
      "\n",
      "Sample: 48/100 -- Learning Rate: 0.013096 | Minibatch Size: 318\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 29.76s | loss: 0.1623 | acc: 0.9505 | Val loss: 0.1860 | Val acc: 0.9448 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 30.01s | loss: 0.1454 | acc: 0.9503 | Val loss: 0.1945 | Val acc: 0.9416 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 59secs 850.75ms ***************************\n",
      "\n",
      "Sample: 49/100 -- Learning Rate: 0.000324 | Minibatch Size: 124\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 75.59s | loss: 0.2433 | acc: 0.9343 | Val loss: 0.2499 | Val acc: 0.9304 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 79.53s | loss: 0.1617 | acc: 0.9569 | Val loss: 0.1915 | Val acc: 0.9496 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 35secs 238.42ms ***************************\n",
      "\n",
      "Sample: 50/100 -- Learning Rate: 0.001447 | Minibatch Size: 900\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.98s | loss: 0.2982 | acc: 0.9150 | Val loss: 0.2929 | Val acc: 0.9208 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.13s | loss: 0.1868 | acc: 0.9475 | Val loss: 0.2021 | Val acc: 0.9472 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 199.70ms ***************************\n",
      "\n",
      "Sample: 51/100 -- Learning Rate: 0.000451 | Minibatch Size: 213\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 44.91s | loss: 0.2570 | acc: 0.9274 | Val loss: 0.2613 | Val acc: 0.9280 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 45.49s | loss: 0.1639 | acc: 0.9569 | Val loss: 0.1874 | Val acc: 0.9480 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 30secs 496.94ms ***************************\n",
      "\n",
      "Sample: 52/100 -- Learning Rate: 0.049771 | Minibatch Size: 711\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 13.07s | loss: 0.6983 | acc: 0.7599 | Val loss: 0.6821 | Val acc: 0.7552 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.86s | loss: 0.4057 | acc: 0.8904 | Val loss: 0.4390 | Val acc: 0.8880 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 0.88ms ***************************\n",
      "\n",
      "Sample: 53/100 -- Learning Rate: 0.000718 | Minibatch Size: 747\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.78s | loss: 0.3431 | acc: 0.8994 | Val loss: 0.3185 | Val acc: 0.9152 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 14.09s | loss: 0.2338 | acc: 0.9341 | Val loss: 0.2309 | Val acc: 0.9392 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 932.36ms ***************************\n",
      "\n",
      "Sample: 54/100 -- Learning Rate: 0.000729 | Minibatch Size: 510\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 22.60s | loss: 0.2886 | acc: 0.9170 | Val loss: 0.2760 | Val acc: 0.9304 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 20.93s | loss: 0.1979 | acc: 0.9456 | Val loss: 0.2069 | Val acc: 0.9448 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 43secs 602.43ms ***************************\n",
      "\n",
      "Sample: 55/100 -- Learning Rate: 0.022788 | Minibatch Size: 462\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 18.12s | loss: 0.2374 | acc: 0.9289 | Val loss: 0.2440 | Val acc: 0.9224 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 18.76s | loss: 0.1469 | acc: 0.9529 | Val loss: 0.1984 | Val acc: 0.9448 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 36secs 966.34ms ***************************\n",
      "\n",
      "Sample: 56/100 -- Learning Rate: 0.007355 | Minibatch Size: 94\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 84.12s | loss: 0.2104 | acc: 0.9367 | Val loss: 0.2440 | Val acc: 0.9304 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 88.28s | loss: 0.0874 | acc: 0.9725 | Val loss: 0.1285 | Val acc: 0.9648 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 52secs 514.54ms ***************************\n",
      "\n",
      "Sample: 57/100 -- Learning Rate: 0.000241 | Minibatch Size: 574\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 18.61s | loss: 0.5989 | acc: 0.8607 | Val loss: 0.5606 | Val acc: 0.8840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 20.18s | loss: 0.3343 | acc: 0.9106 | Val loss: 0.3123 | Val acc: 0.9208 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 38secs 872.48ms ***************************\n",
      "\n",
      "Sample: 58/100 -- Learning Rate: 0.000154 | Minibatch Size: 380\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 30.99s | loss: 0.6506 | acc: 0.8584 | Val loss: 0.6129 | Val acc: 0.8784 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 28.68s | loss: 0.3578 | acc: 0.9099 | Val loss: 0.3343 | Val acc: 0.9200 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 59secs 769.47ms ***************************\n",
      "\n",
      "Sample: 59/100 -- Learning Rate: 0.000738 | Minibatch Size: 991\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.23s | loss: 0.3841 | acc: 0.8889 | Val loss: 0.3520 | Val acc: 0.8984 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 11.22s | loss: 0.2613 | acc: 0.9258 | Val loss: 0.2556 | Val acc: 0.9320 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 525.48ms ***************************\n",
      "\n",
      "Sample: 60/100 -- Learning Rate: 0.000689 | Minibatch Size: 404\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 26.85s | loss: 0.2647 | acc: 0.9261 | Val loss: 0.2601 | Val acc: 0.9288 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 20.79s | loss: 0.1817 | acc: 0.9503 | Val loss: 0.2012 | Val acc: 0.9520 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 47secs 712.84ms ***************************\n",
      "\n",
      "Sample: 61/100 -- Learning Rate: 0.000127 | Minibatch Size: 86\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 97.91s | loss: 0.3261 | acc: 0.9153 | Val loss: 0.3124 | Val acc: 0.9200 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 114.24s | loss: 0.2268 | acc: 0.9404 | Val loss: 0.2325 | Val acc: 0.9424 \n",
      "\n",
      "*************************** Total Training Time = 0hr 3mins 32secs 268.73ms ***************************\n",
      "\n",
      "Sample: 62/100 -- Learning Rate: 0.001260 | Minibatch Size: 530\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 21.92s | loss: 0.2387 | acc: 0.9326 | Val loss: 0.2437 | Val acc: 0.9392 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 21.53s | loss: 0.1721 | acc: 0.9497 | Val loss: 0.2029 | Val acc: 0.9456 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 43secs 532.30ms ***************************\n",
      "\n",
      "Sample: 63/100 -- Learning Rate: 0.005278 | Minibatch Size: 46\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 178.49s | loss: 0.1591 | acc: 0.9517 | Val loss: 0.2133 | Val acc: 0.9432 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 161.27s | loss: 0.1030 | acc: 0.9697 | Val loss: 0.1682 | Val acc: 0.9600 \n",
      "\n",
      "*************************** Total Training Time = 0hr 5mins 39secs 922.83ms ***************************\n",
      "\n",
      "Sample: 64/100 -- Learning Rate: 0.042796 | Minibatch Size: 233\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 32.05s | loss: 0.3089 | acc: 0.9171 | Val loss: 0.3704 | Val acc: 0.9096 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 26.36s | loss: 0.2186 | acc: 0.9346 | Val loss: 0.2732 | Val acc: 0.9384 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 58secs 489.10ms ***************************\n",
      "\n",
      "Sample: 65/100 -- Learning Rate: 0.000320 | Minibatch Size: 512\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 13.87s | loss: 0.4318 | acc: 0.8841 | Val loss: 0.3962 | Val acc: 0.8960 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 13.72s | loss: 0.2726 | acc: 0.9265 | Val loss: 0.2609 | Val acc: 0.9304 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 27secs 653.78ms ***************************\n",
      "\n",
      "Sample: 66/100 -- Learning Rate: 0.012054 | Minibatch Size: 986\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 7.08s | loss: 0.4179 | acc: 0.8843 | Val loss: 0.3848 | Val acc: 0.8880 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 7.13s | loss: 0.1888 | acc: 0.9452 | Val loss: 0.2094 | Val acc: 0.9344 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 14secs 262.69ms ***************************\n",
      "\n",
      "Sample: 67/100 -- Learning Rate: 0.075550 | Minibatch Size: 463\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 13.04s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.93s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 26secs 34.59ms ***************************\n",
      "\n",
      "Sample: 68/100 -- Learning Rate: 0.002825 | Minibatch Size: 129\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 58.61s | loss: 0.1583 | acc: 0.9507 | Val loss: 0.2022 | Val acc: 0.9408 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 63.58s | loss: 0.0751 | acc: 0.9770 | Val loss: 0.1096 | Val acc: 0.9688 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 2secs 284.54ms ***************************\n",
      "\n",
      "Sample: 69/100 -- Learning Rate: 0.087172 | Minibatch Size: 684\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 11.78s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.05s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 23secs 901.24ms ***************************\n",
      "\n",
      "Sample: 70/100 -- Learning Rate: 0.018487 | Minibatch Size: 309\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 25.78s | loss: 0.1934 | acc: 0.9415 | Val loss: 0.2260 | Val acc: 0.9360 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 25.54s | loss: 0.1225 | acc: 0.9623 | Val loss: 0.1775 | Val acc: 0.9504 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 51secs 394.46ms ***************************\n",
      "\n",
      "Sample: 71/100 -- Learning Rate: 0.035877 | Minibatch Size: 656\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.49s | loss: 0.4512 | acc: 0.8689 | Val loss: 0.4306 | Val acc: 0.8832 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.93s | loss: 0.2233 | acc: 0.9355 | Val loss: 0.2497 | Val acc: 0.9312 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 481.20ms ***************************\n",
      "\n",
      "Sample: 72/100 -- Learning Rate: 0.000709 | Minibatch Size: 106\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 76.73s | loss: 0.1803 | acc: 0.9481 | Val loss: 0.2051 | Val acc: 0.9456 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 76.30s | loss: 0.0896 | acc: 0.9758 | Val loss: 0.1348 | Val acc: 0.9656 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 33secs 125.46ms ***************************\n",
      "\n",
      "Sample: 73/100 -- Learning Rate: 0.000184 | Minibatch Size: 667\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 13.58s | loss: 0.9001 | acc: 0.8320 | Val loss: 0.8688 | Val acc: 0.8472 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 13.12s | loss: 0.4455 | acc: 0.8906 | Val loss: 0.4127 | Val acc: 0.9032 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 26secs 766.60ms ***************************\n",
      "\n",
      "Sample: 74/100 -- Learning Rate: 0.002747 | Minibatch Size: 861\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 10.26s | loss: 0.2707 | acc: 0.9233 | Val loss: 0.2690 | Val acc: 0.9240 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 10.13s | loss: 0.1475 | acc: 0.9584 | Val loss: 0.1654 | Val acc: 0.9544 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 20secs 452.40ms ***************************\n",
      "\n",
      "Sample: 75/100 -- Learning Rate: 0.002315 | Minibatch Size: 979\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 9.56s | loss: 0.3208 | acc: 0.9105 | Val loss: 0.3160 | Val acc: 0.9072 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.39s | loss: 0.1688 | acc: 0.9518 | Val loss: 0.1836 | Val acc: 0.9536 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 19secs 4.25ms ***************************\n",
      "\n",
      "Sample: 76/100 -- Learning Rate: 0.024997 | Minibatch Size: 485\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 15.44s | loss: 0.2866 | acc: 0.9108 | Val loss: 0.2913 | Val acc: 0.9088 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 14.56s | loss: 0.1623 | acc: 0.9477 | Val loss: 0.1993 | Val acc: 0.9400 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 30secs 60.94ms ***************************\n",
      "\n",
      "Sample: 77/100 -- Learning Rate: 0.006782 | Minibatch Size: 1001\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 8.96s | loss: 0.3371 | acc: 0.9020 | Val loss: 0.3072 | Val acc: 0.9136 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 8.34s | loss: 0.1723 | acc: 0.9489 | Val loss: 0.1877 | Val acc: 0.9440 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 17secs 360.41ms ***************************\n",
      "\n",
      "Sample: 78/100 -- Learning Rate: 0.002528 | Minibatch Size: 745\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 10.60s | loss: 0.2571 | acc: 0.9246 | Val loss: 0.2594 | Val acc: 0.9288 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.20s | loss: 0.1752 | acc: 0.9453 | Val loss: 0.1821 | Val acc: 0.9456 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 22secs 863.49ms ***************************\n",
      "\n",
      "Sample: 79/100 -- Learning Rate: 0.000161 | Minibatch Size: 863\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 10.68s | loss: 1.2016 | acc: 0.7891 | Val loss: 1.1843 | Val acc: 0.7952 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 10.91s | loss: 0.6273 | acc: 0.8662 | Val loss: 0.5906 | Val acc: 0.8864 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 21secs 659.97ms ***************************\n",
      "\n",
      "Sample: 80/100 -- Learning Rate: 0.000102 | Minibatch Size: 337\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 24.79s | loss: 0.8701 | acc: 0.8345 | Val loss: 0.8391 | Val acc: 0.8544 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 24.92s | loss: 0.4482 | acc: 0.8947 | Val loss: 0.4178 | Val acc: 0.9064 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 49secs 780.03ms ***************************\n",
      "\n",
      "Sample: 81/100 -- Learning Rate: 0.091366 | Minibatch Size: 262\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 27.34s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 27.61s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 55secs 21.02ms ***************************\n",
      "\n",
      "Sample: 82/100 -- Learning Rate: 0.007921 | Minibatch Size: 610\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 13.63s | loss: 0.2704 | acc: 0.9189 | Val loss: 0.2672 | Val acc: 0.9296 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 13.75s | loss: 0.1330 | acc: 0.9595 | Val loss: 0.1578 | Val acc: 0.9560 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 27secs 452.86ms ***************************\n",
      "\n",
      "Sample: 83/100 -- Learning Rate: 0.005428 | Minibatch Size: 988\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 9.07s | loss: 0.3088 | acc: 0.9121 | Val loss: 0.2828 | Val acc: 0.9200 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 9.00s | loss: 0.1647 | acc: 0.9531 | Val loss: 0.1806 | Val acc: 0.9528 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 18secs 130.97ms ***************************\n",
      "\n",
      "Sample: 84/100 -- Learning Rate: 0.001682 | Minibatch Size: 470\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 17.72s | loss: 0.2079 | acc: 0.9399 | Val loss: 0.2226 | Val acc: 0.9416 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 17.85s | loss: 0.1320 | acc: 0.9621 | Val loss: 0.1679 | Val acc: 0.9544 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 35secs 631.97ms ***************************\n",
      "\n",
      "Sample: 85/100 -- Learning Rate: 0.003779 | Minibatch Size: 582\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 14.40s | loss: 0.2002 | acc: 0.9417 | Val loss: 0.2095 | Val acc: 0.9416 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 14.64s | loss: 0.1187 | acc: 0.9640 | Val loss: 0.1494 | Val acc: 0.9584 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 29secs 100.68ms ***************************\n",
      "\n",
      "Sample: 86/100 -- Learning Rate: 0.000603 | Minibatch Size: 501\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 16.83s | loss: 0.3081 | acc: 0.9107 | Val loss: 0.2878 | Val acc: 0.9208 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 17.12s | loss: 0.2031 | acc: 0.9450 | Val loss: 0.2073 | Val acc: 0.9448 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 34secs 11.28ms ***************************\n",
      "\n",
      "Sample: 87/100 -- Learning Rate: 0.021925 | Minibatch Size: 136\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 55.38s | loss: 0.2295 | acc: 0.9308 | Val loss: 0.2654 | Val acc: 0.9240 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 54.41s | loss: 0.1783 | acc: 0.9441 | Val loss: 0.2200 | Val acc: 0.9344 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 49secs 874.17ms ***************************\n",
      "\n",
      "Sample: 88/100 -- Learning Rate: 0.089140 | Minibatch Size: 296\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 24.92s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 24.53s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 49secs 509.47ms ***************************\n",
      "\n",
      "Sample: 89/100 -- Learning Rate: 0.000114 | Minibatch Size: 195\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 41.13s | loss: 0.5088 | acc: 0.8802 | Val loss: 0.4748 | Val acc: 0.8968 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 42.18s | loss: 0.3149 | acc: 0.9199 | Val loss: 0.2975 | Val acc: 0.9272 \n",
      "\n",
      "*************************** Total Training Time = 0hr 1mins 23secs 386.87ms ***************************\n",
      "\n",
      "Sample: 90/100 -- Learning Rate: 0.092969 | Minibatch Size: 387\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 18.82s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 19.19s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 38secs 78.46ms ***************************\n",
      "\n",
      "Sample: 91/100 -- Learning Rate: 0.004803 | Minibatch Size: 423\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 19.26s | loss: 0.1722 | acc: 0.9499 | Val loss: 0.1888 | Val acc: 0.9496 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 19.53s | loss: 0.0986 | acc: 0.9707 | Val loss: 0.1391 | Val acc: 0.9608 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 38secs 864.33ms ***************************\n",
      "\n",
      "Sample: 92/100 -- Learning Rate: 0.070832 | Minibatch Size: 322\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 22.87s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 22.53s | loss: nan | acc: 0.0977 | Val loss: nan | Val acc: 0.0840 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 45secs 469.94ms ***************************\n",
      "\n",
      "Sample: 93/100 -- Learning Rate: 0.000483 | Minibatch Size: 438\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 19.94s | loss: 0.3145 | acc: 0.9101 | Val loss: 0.2949 | Val acc: 0.9208 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 19.32s | loss: 0.2196 | acc: 0.9403 | Val loss: 0.2210 | Val acc: 0.9440 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 39secs 325.92ms ***************************\n",
      "\n",
      "Sample: 94/100 -- Learning Rate: 0.008684 | Minibatch Size: 92\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 70.29s | loss: 0.1578 | acc: 0.9529 | Val loss: 0.1894 | Val acc: 0.9448 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 75.87s | loss: 0.1078 | acc: 0.9678 | Val loss: 0.1658 | Val acc: 0.9560 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 26secs 255.66ms ***************************\n",
      "\n",
      "Sample: 95/100 -- Learning Rate: 0.000256 | Minibatch Size: 458\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 19.12s | loss: 0.4813 | acc: 0.8768 | Val loss: 0.4420 | Val acc: 0.8928 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 18.68s | loss: 0.2917 | acc: 0.9223 | Val loss: 0.2779 | Val acc: 0.9272 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 37secs 865.31ms ***************************\n",
      "\n",
      "Sample: 96/100 -- Learning Rate: 0.002642 | Minibatch Size: 543\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 16.02s | loss: 0.1959 | acc: 0.9429 | Val loss: 0.2102 | Val acc: 0.9448 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 15.77s | loss: 0.1290 | acc: 0.9618 | Val loss: 0.1615 | Val acc: 0.9544 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 31secs 857.97ms ***************************\n",
      "\n",
      "Sample: 97/100 -- Learning Rate: 0.004488 | Minibatch Size: 388\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==========> 100%] - 21.42s | loss: 0.1579 | acc: 0.9542 | Val loss: 0.1740 | Val acc: 0.9504 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 20.89s | loss: 0.0854 | acc: 0.9758 | Val loss: 0.1211 | Val acc: 0.9640 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 42secs 376.66ms ***************************\n",
      "\n",
      "Sample: 98/100 -- Learning Rate: 0.031502 | Minibatch Size: 645\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 12.40s | loss: 0.3661 | acc: 0.8884 | Val loss: 0.3550 | Val acc: 0.8928 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 12.84s | loss: 0.2085 | acc: 0.9382 | Val loss: 0.2390 | Val acc: 0.9344 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 25secs 310.89ms ***************************\n",
      "\n",
      "Sample: 99/100 -- Learning Rate: 0.001374 | Minibatch Size: 106\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 74.02s | loss: 0.1720 | acc: 0.9482 | Val loss: 0.2105 | Val acc: 0.9352 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 74.32s | loss: 0.0664 | acc: 0.9805 | Val loss: 0.1103 | Val acc: 0.9680 \n",
      "\n",
      "*************************** Total Training Time = 0hr 2mins 28secs 442.34ms ***************************\n",
      "\n",
      "Sample: 100/100 -- Learning Rate: 0.002030 | Minibatch Size: 473\n",
      "==========================================================================================================\n",
      "\n",
      "Epoch: 1/2\n",
      "15000/15000 [==========> 100%] - 17.29s | loss: 0.2011 | acc: 0.9424 | Val loss: 0.2186 | Val acc: 0.9440 \n",
      "Epoch: 2/2\n",
      "15000/15000 [==========> 100%] - 17.69s | loss: 0.1238 | acc: 0.9631 | Val loss: 0.1588 | Val acc: 0.9576 \n",
      "\n",
      "*************************** Total Training Time = 0hr 0mins 35secs 43.83ms ***************************\n",
      "==========================================================================================================\n",
      "\n",
      "\n",
      "*************************** Total Search Time = 1hr 52mins 30secs 741.22ms ***************************\n",
      "\n",
      "\n",
      "Coarse Search Summary: \n",
      "\n",
      "+================+===============+================+\n",
      "| Validation Acc | Learning Rate | Minibatch Size |\n",
      "+================+===============+================+\n",
      "| 0.95120\t | 0.00036\t | 198\t\t  |\n",
      "| 0.96000\t | 0.00985\t | 113\t\t  |\n",
      "| 0.95360\t | 0.01309\t | 369\t\t  |\n",
      "| 0.95760\t | 0.00364\t | 470\t\t  |\n",
      "| 0.96400\t | 0.00061\t | 105\t\t  |\n",
      "| 0.96000\t | 0.00381\t | 596\t\t  |\n",
      "| 0.96640\t | 0.00381\t | 147\t\t  |\n",
      "| 0.96320\t | 0.00045\t | 51\t\t  |\n",
      "| 0.95520\t | 0.00648\t | 671\t\t  |\n",
      "| 0.96720\t | 0.00053\t | 24\t\t  |\n",
      "| 0.96640\t | 0.00365\t | 340\t\t  |\n",
      "| 0.95600\t | 0.00018\t | 36\t\t  |\n",
      "| 0.95280\t | 0.00051\t | 212\t\t  |\n",
      "| 0.96480\t | 0.00735\t | 94\t\t  |\n",
      "| 0.95200\t | 0.00069\t | 404\t\t  |\n",
      "| 0.96000\t | 0.00528\t | 46\t\t  |\n",
      "| 0.96880\t | 0.00282\t | 129\t\t  |\n",
      "| 0.95040\t | 0.01849\t | 309\t\t  |\n",
      "| 0.96560\t | 0.00071\t | 106\t\t  |\n",
      "| 0.95440\t | 0.00275\t | 861\t\t  |\n",
      "| 0.95360\t | 0.00231\t | 979\t\t  |\n",
      "| 0.95600\t | 0.00792\t | 610\t\t  |\n",
      "| 0.95280\t | 0.00543\t | 988\t\t  |\n",
      "| 0.95440\t | 0.00168\t | 470\t\t  |\n",
      "| 0.95840\t | 0.00378\t | 582\t\t  |\n",
      "| 0.96080\t | 0.00480\t | 423\t\t  |\n",
      "| 0.95600\t | 0.00868\t | 92\t\t  |\n",
      "| 0.95440\t | 0.00264\t | 543\t\t  |\n",
      "| 0.96400\t | 0.00449\t | 388\t\t  |\n",
      "| 0.96800\t | 0.00137\t | 106\t\t  |\n",
      "| 0.95760\t | 0.00203\t | 473\t\t  |\n",
      "+================+===============+================+\n",
      "New Search Space for Learning Rate: [0.000162,0.020336]\n",
      "New Search Space for Minibatch Size: [21,1086]\n",
      "Best Score: 0.968800 \n",
      "Best Hyper Params:\n",
      " Learning Rate: 0.002825\n",
      " Minibatch Size: 129\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAGdCAYAAADHQK08AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5hbdYH/8c8306TpJUxoS0GgAu0EV0G57PyAzW9hFS1rkCq76yr34oWuqLu4q7uP+ttnWXRXvK1aZb10FXfwArKiC1WyWllRfLJUiiiKoGlLkYoslJIhhaYnbb6/P04yncxkZpKZnJxL3q/n6dPJyZnkm++cyXzyvRprrQAAAOCdmN8FAAAAiDoCFwAAgMcIXAAAAB4jcAEAAHiMwAUAAOAxAhcAAIDHCFySjNEWY/TX425faozWdfHxY8bob43Rzcboa8boBmN0ZLcev8XzHWmMbm7jvHXGKG+MvmqM/sMY/bFXZQIAoJ+ZIK/DtWzZMnvsscd2/H2N12SMaev8hx76gubNG9Wxx/6D5s3bo6eeOle12nwddtg3O37uVkZHz1C5fJqOOupTMsaqWj1UsZijgYFn5/S41sZkTG3SccdZpp0736mVK98z7fc/+eSfKBbbp6VLb5fjHK6HH36/jj/+ShlzYA5l6qzu0T1BrvunnnpKBw4caCqbtVYDAwNaunSpjyXrniDXf9RR9/6h7pvde++9u6y1h7W6L9CBa3h42G7ZsqXj76tUKpKkZDLZ1vlnnim98Y3S3r3SW98qfelL7tfr1klPPy1de630+OPuue98p3TSSdLrXy99/vPS4sXSy1/uHn/Vq6R/+AfpvPOk0047+Phf+Yr0299Kf/d3k5/77rulz31Ochzp6KOlq6+WFi6U/u3fpLvukioV9/ne+17JGLdMJ50k/exn0llnSeeeK33gA+7jS9J73iMtWyb91V9JJ58s3X+/dNhh0sc+Js2f3/zcGzZICxZIl17q3j7nHOmmm6QlS6RvftP9V61KK1ZI73uflExK//iP0qJF0oMPSrt2SVdd5b7+Wk368Iele+45oOc9zyoWm6fXvMa978EHpY9/XHruOSmddh9j2bL2f55oT6fXfS8Vi0Xl83nFYjHF43FVq1XVajXlcjllMhm/i9cVQa7/qKPu/UPdNzPG3GutHW51H12Kda97nZTPS3v2NB//6Eeliy6SbrjBDRTvf797vBF6tm93g9J997nHf/5z6cQTmx9j9Wo3PF10kRs8fvUr93ipJH3hC9KnP+2Gshe9yP1fcgPdDTdIN98s7dvnfn9DueyGpUsukT7yEenUU6Ubb3S/d+VK95zf/MZ9TTffLKVS0h13TP/6H3pIev7z3bAlSWef7T7/jTdKxx4r3XrrwXN37XLD5ic+IX3qU+6x739feuwx6Utfquo979mvn//cPb5/v1vGD31I+vKXpVe/2n29iIZisaiRkRGtX79eIyMjKhaLLc/LZDLK5XJKpVKqVCpKpVKRClsAMJN5fhcgKBYtcluobrqpuSXoxz+WHn744O1nn3Vbak45RfrJT6TnPU967Wulb3xDeuIJ6ZBD3Baq8ZYvl265RdqyRbrnHunKK6UPftANUtu3S296k3tetSq9+MXu11u2SCMjbgvXM8+4Qeqss9z7zjnn4GPfc490zTXu17GY2+L2zDPSUUdJxx/vHn/hC6Xf/a716/7qV92WrN/+9mB4kqRt29xgVC67rX1nnHHwvpe+1H2ulSul3bvdYz/9qfSKV7jHly6Vhuv5/pFHpK1bpbe9zb194ACtW1ExvtUqmUyqXC4rn89LUssglclkCFgA+haBa5yLLpIuvlhas+bgsVpN+uIXJ3fHnXqq9B//4XY1vu1tbgvPHXe4QayVRELKZt1/S5ZId97phpjTT3e7BMdzHDeQfelL0uGHu61ZjnPw/nZabuPxg1/HYm7Qmeo1X3qp9N//7XZn3nqrW9Z//Ee3de/446WNG6V7721+LQ2NHumpeqatlVatcusQ0VIoFBSLxZSoXxCJREKO46hQKBCsAGACuhTHOeQQt/tvfPfZGWdIX/vawdu//rX7/+GHu12Cjz7qtiadfLIbkFoFrocekp580v26VpOKRbdl7MUvdrslH33Uva9ScbsC9+1zb6fTbmva9743dZlPO036+tcPPvazz0rbt2/Xjh07xrp5Hm8MQJvG2We7LWHf+pZ7+9ln3Zao/fvdrtaZnHyyG9pqNbfVqxHQjjnGHQd3//3u7f373VY9hF+pVFJ8fLKXFI/HVSqVfCoRAAQXLVwTXHJJc8D62791xx9dcIHbSnTKKe4Adskdq9VoOTrlFOm669zgMdHu3dI//dPBVqoTT3THaDVakv7f/zt431vf6o6lOv9895wjj5ROOGHq8r7rXe5j33qrNDAgXXjhI/rpT7+v/fvPGuvmuf/++3X88UbS4dO+9iuucMty/vlut+fll0tHHCENDbnBbzpnn+12v15ySVwrVlideKLbvRmPu2PfPvIRd3zcgQPShRceHGuG8Eqn0yqXy2MtXJJUrVaVTqd9LBUABBOzFCNmZGRk0h9Bx3GUSqW0du1aT5/7ueekWKyi0VFp3bqkrr/eHc+F3uj1dd8PMw870c/vO36j7v1D3TebbpYiLVwRUyqVJl34vermecc7pNHRuKpV6c1vJmxFXSNUFQoFlUolpdNpZbPZvgxbADATAlfE+NnNs2GDVKlUJUnJ5IDnzwf/MfMQANrDoPmIyWazqtVqchxH1lo5jqNaraZsNut30QAA6Fu0cEUM3TwAAAQPgSuC6OYBACBY6FIEAADwWN+3cB37iWP1yOgjfhcjMpJyZ0hWVPG5JP2HuvcX9e8f6t4/Yan7YwaP0Y537PC1DIEMXMaYNZLWDA0Nef5cj4w+Int1cNciCxvWZPEPde8v6t8/1L1/wlL35hrjdxGCGbistRslbRweHr7C77IgXIrFIhMGAACBE8jABczG+JXPG9sa5esbQc4mdBHeAADdwqB5REahUFAsFlMikZAxRolEQrFYTIVCoePHaoS3crncFN6KxaIHJQcARB2BC5FRKpUUj8ebjs12W6NuhjcAAAhciIx0Oq1qtdp0bLbbGnUzvAEAQOBCZHRzW6NuhjcAAAhciIxMJqNcLqdUKqVKpaJUKqVcLjerge7sSQkA6CZmKSJSurWtEXtSAgC6icAFTIE9KQEA3UKXIgAAgMcIXAAAAB4jcAEAAHiMwAUAAOAxAhcAAIDHmKUIAECb2NQes0XgAgCgDY1N7WOxWNOm9pIIXZgRXYoAALSBTe0xFwQuAADawKb2mAsCFwAAbWBTe8wFgQsAgDawqT3mgkHzAAC0gU3tMRcELgAA2sSm9pgtuhQBAAA8RuACAADwGIELAADAY4zhgm/YIgMA0C8IXPBFGLfIICACAGaLwAVfjN8iQ5ISiYQcx1GhUAhkiOlVQCTUAUA0MYYLvgjbFhm92EOtEerK5XJTqCsWi117DgCAPwhc8EXYtsjoRUBkY1wAiC4CF3wRti0yehEQw9bqBwBoH4ELvshkMsrlckqlUqpUKkqlUsrlcoEdr9SLgBi2Vj8AQPsYNA/fhGmLjF7soZbNZpXP5+U4juLxuKrVaqBb/QAA7SNwAW3yOiCyMS4Ar3U6E5qZ091D4AICJEytfgDCpdPlbcK4XmKQMYYLAIA+0OlMaGZOdxeBCwCAPtDpTGhmTncXgQsAgD7Q6UxoZk53F4ELAIA+0OnyNmFbLzHoGDQPAEAf6HQmNDOnu4vABQBAn+h0JjQzp7uHLkUAAACPEbgAAAA8RuACAADwGIELAADAYwQuAAAAj/UscBljzjfG/Jsx5lZjzDm9el4AAAC/tbUshDHmeknnSXrCWnviuOOvlLRe0oCkz1trPzjVY1hr/1PSfxpjDpX0UUnfnUvB+w07tgMAEF7trsP175Kuk3RD44AxZkDSv0paLWmnpHuMMbfJDV/XTvj+N1prn6h//ff175uRtVaVSqXNIh7UyfcklZzVc/TStm3btGnTprFNREdHR/Xtb39bq1ev1qpVq/wuXpOg12WUUff+ov79Q937Jyx1H4S/9W0FLmvtD40xx044fJqkrdba7ZJkjLlJ0mustdfKbQ1rYowxkj4oKW+t/clUz2WMWSdpnSStWLGineJF3ubNm8fCliQlEgk5jqPNmzcHLnABAIDJ5rLS/FGSHh13e6ek06c5/y8lvULSoDFmyFr72VYnWWs3SNogScPDwzaZTM66gO18b0WVts7zU7lcVjKZlJtZXfPnzx87HkRBLVc/oO79Rf37h7r3T9DrPgh/6+cSuEyLY3aqk621n5T0yTk8X99Kp9Mql8tjLVwSO7YDABAmc5mluFPS+D6/oyU9NrfioBV2bAcAINzm0sJ1j6SMMeY4Sb+VdIGki7pSKjRhx3YAAMKt3WUhbpT0UknLjDE7JV1trf2CMebtkr4jd2bi9dbaBzwraZ9jx3YAAMKr3VmKF05x/HZJt3e1RAAAABEzly5FdAELmgIAEH2B3EvRGLPGGLNhdHTU76J4qlgsKp/Pjy3vUC6Xlc/nVSwW/S4aAADookAGLmvtRmvtusHBQb+L4qlCoTC2oKkxRolEQrFYTIVCwe+iAQCALgpk4OoXpVJJ8Xi86Vg8HlepVPKpRAAAwAsELh+l02lVq9WmYyxoCgBA9BC4fMSCpgAA9AdmKfqIBU0BAOgPBC6fsaApED0s9wJgIgIXAHRRY7mXWCzWtNyLJEIX0McCOYarX9bhAhA9LPcCoJVABq5+WYcLQPSw3AuAVgIZuAAgrFjuBUArjOEKAAbYAtGRzWaVz+flOI7i8biq1SrLvQAgcPmNAbZAtLDcC4BWCFw+Gz/AVpISiYQcx1GhUOANGggplnsBMBFjuHzGAFsAAKKPwOUzBtgCABB9BC6fsZ8iAADRxxgunzHAFgAQVtu2bdPmzZtVLpf5+zWDQAYuY8waSWuGhob8LkpPMMAWABA2xWJRmzZtYpZ9mwLZpchK8wAABBvbWHUmkIELAAAEG7PsOxPILkUAQGfYsQLdNtM1lU6nNTo6OraOpMQs++nQwgUAIdfYsaJcLjeNpSkWi34XDSHVzjXFLPvOELgAIOQYS4Nua+eaymQyWr16tRYvXqxKpaJUKqVcLkfL6hToUgSAkCuVSkomk03HGEuDuWj3mlq1apVWrVo16VxMRgsXAIQcO1ag27imuo/ABQAhx1gadBvXVPfRpQgAIceOFeg2rqnuI3ABQASwYwW6jWuquwLZpWiMWWOM2TA6Oup3UQAAAOYskIGLrX0AAECUBDJwAQAARAmBCwAAwGMMmgcAAFNin87uIHABAICWGnsqxmKxpj0VJRG6OkSXIgAAaIl9OruHFq420aQKAOg37NPZPbRwtaHRpFoul5uaVIvFot9FAwDAM+yp2D0ErjbQpAoA6Efsqdg9dCm2gSZVAEA/Yk/F7iFwtSGdTqtcLiuRSIwdo0kVANAP2FOxO+hSbANNqgAAYC4C2cJljFkjac3Q0JDfRZFEkyqihRm3ANB7gQxc1tqNkjYODw9f4XdZGmhSRRSwiCEA+IMuRaCPMOMWAPxB4AL6SKlUUjwebzrGjFsA8B6BC+gjLGIIAP4I5BguAFOby6D3bDarfD4vx3EUj8dVrVaZcQsAPUDgAkJkukHvK1asmPH7mXELAP4gcAEhMn7QuyQlEgk5jqNCoaDXv/71bT0GM24BoPcYwwWECIPeASCcCFxAiDDoHQDCicAFhAjbTAFAODGGCwiR6Qa9VyoVn0sHAJgKgQsIGQa9A0D40KUIAADgMQIXAACAxwhcAAAAHiNwAQAAeCyQg+aNMWskrRkaGvK7KJExl/33ALQ2/vcqlUrp9NNP1wknnOB3sQAEUCADl7V2o6SNw8PDV/hdliiYbv89Qhcwvak+rEz8vdqzZ482bdqkRCLB7xWASehS7APj998zxiiRSCgWi6lQKPhdNCDQGqGqXC43fVhphDB+rwC0K5AtXOiuUqmkZDLZdIz997zVr124UXvd020Wzu8VgE7QwtUH2H+vt6ZrFYmyKL7u6TYL5/cKQCcIXH2A/fd6q1+7mqL4uqcLVfxeAegEgasPZDIZ5XI5pVIpVSoVpVIp5XK5UHf1BNl0rSJRFsXXPV2omvh7tXjxYq1evZrfKwAtMYarT7D/Xu+k02mVy+WxcT9Sf3Q1RfF1T7dZeOP+xtdsHg5gOgQuoMuy2azy+bwcx1E8Hle1Wu2Lrqaovm4+rADoBgIX0GUztYpEVb++bgBoB4EL8EC/tor06+sGgJkwaB4AAMBjBC4AAACPEbgAAAA8xhiukNtf268tj23Ro6OPyjngaGF8oU464iStPHSl30UDAAB1BK6Qstbql0/+Ut/b/j0tX7RcLz78xUoMJDRaGdXGX23UYYsO0zmrztGyhcv8LioAAH2PwBVShUcLuu/x+/TqF7xaxx16XNN9pzzvFP34tz/WF+/7otaevFbLFy33qZQAAEBiDFcoPfz0w7p759267KTLJoUtSZoXm6fsiqzOWXWObvrFTaoeqLZ4FAAA0CsErpDZX9uvb/36Wzrv+PN0yPxDpj33pCNO0pGpI/WDR34w5TmnnSZddJF04YXSxRdL998/u3J99avSVDub7N8vfepT0p/8ifS610mXXSY19jM+88zOnueWW6Rvf3t2ZQQAwC90KYbM9qe3a1FikV6w7AVtnb965Wp9dstndfZxZytmJufr+fPdsCRJ//M/0nXXSRs2dF6uG2+Uzj1XSiYn3/eZz0i7dklf+5qUSEi7d0v33tv5c0jSn/3Z7L4PAAA/EbhCpvhUUS9Y2l7YkqTB5KAGk4Pa+cxOPX/w+dOe++yzUip18PYNN0jf+57kONLLXib9xV9Ie/dK73639MQT0oED0pvf7AaoJ59070+l5um66/aPPUalIn3zm9LGjW7YkqQlS6TVqw8+z6c/Ld11lxv+PvYx9/7f/U563/ukp5+WDj1Uuvpq6Ygj3DC4YIF06aXSo49K117rnhOLSR/6kHT00a3LDQCAnwIZuIwxayStGRoa8rsogWKt1dbdW3XBiRd09H1DS4a0dffWloFr3z63S3HfPrcV6rOfdY/ffbcbaEZGJGulv/kb6Sc/kUol6bDDpPXr3fP27JEWL5a+8hXpc5+Tksn9TY//6KNuUFq0qHXZ9u6VTjxReutbpU9+0g1nb3qT9OEPS696lXTeedJtt0kf+Yj0L//S/L1///fS5Ze7ocpxpFpt6nKfempHVQYAQFcFcgyXtXajtXbd4OCg30UJlN17d+uAPTBp1mHxuhv0QCanrYedqQcyORWvu6Hp/sySjLbu3tryMRtdirfc4o6zuvpqN6jcfbf77+KLpUsukXbscIPM0JD04x+74ei++9ywNRfx+MFxXL/3e9Jjj7lf33+/9MpXul+fe6700582f99zz7mtai97mXs7kXC7M6cqNwAAfgpkCxdae2bfM1qyYImMMWPHitfdoNoHrleyekCSlCzt0f4PXK+ipMzbL5MkLVmwRM/se2bGx3/JS9wWrKefdkPXG94g/emfTj7vy1+WfvQjd7zXGWdIV1wx9WOuWCE9/rgbkBYunHz/vHlS4+UMDLjdlK2Me8mS3PK1Ml25AQDwSyBbuNCac8BRYiDRfGz9jZpXbU4p86oH5Ky/cex2YiAh54Az4+Pv2OEGnnRa+oM/kG691Q1KkjtmqzFWK5l0W50uvVR66CH3/oULD547XjIpnX++2yVYra9OsWuXdPvt05flpJOk737X/Tqfl04+ufn+RYuk5culO++s14PjjhebqtwA0C3FYlEjIyNav369RkZGVCwW/S4SQoAWrhAxxshOaNqZX9rT8tzxx62sjEzL8xpjuCS3deiaa9wB6GecIT38sNtaJLmB6v3vd7vn1q93z5k3zx1AL7ktSn/5l9KhhzYPmpekK690Zyr++Z+7XX8LFkhvecv0r/Vd73IHzd9ww8FB8xO9733SBz7gjjubN88dND9VuZcsmf75AKAdxWJR+XxesVhMyWRS5XJZ+XxekpTJZHwuHYLMTPwDHiTDw8N2y5YtHX9fpb4gVLLVGgUTmGuM7NXBrYPxHn76Yf3gkR/o8pMvHzv2QCanZIvQVUkv1glF902gvK+sz937Ob0r+y7Py9hJ3aO7qHt/Uf/+6WXdj4yMqFwuK5E42NvgOI5SqZTWrl3r+fMHTViu+179rTfG3GutHW51Hy1cIXLI/EO0e+9uWWvHxnElrrpQ+z9wfVO34v74gBJXXTh2e/fe3TMukgpESbFYVKFQUKlUUjqdVjabpfUBXVEqlSaFi3g8rlKp5FOJEBaM4QqRJQvcfrHdew8OSsq8/TLF3vtGVdKLZeW2bMXe+8axAfOS9HDpYR2XnrwFEBBFjS6fcrnc1OXDOBt0QzqdVrXavF1atVpVOp32qUQIC1q4QsQYo+PSx2lHaYeWLlw6djzz9sukcQFroh2lHfrD5/9hL4oI+K5QKCgWi411+SQSCTmOo0KhQCsX5iybzSqfz8txHMXjcVWrVdVqNWWzWb+LhoAjcIXMseljte3pbfr9I3+/rfOrB6p6rPzYjKvMA1FBl08wRLVbt/Eaovja4C0CV8isWrJK3932XT1XfU4L4y0WtprggScf0NGHHD1pOQkgqtLp9KRBzXT59FbUZ/JlMplIvA70FmO4QuaQ+YfoxOUn6ke/+dGM5+6v7dedO+7UHx3zRz0oGRAM2WxWtVpNjuPIWivHcejy6bHx3brGGCUSCcViMRUKBb+LBviGwBVCZx1zln72+M/0+J7Hpz3vh4/8UEcsPkLHpI/pUckA/2UyGeVyOaVSKVUqFaVSKeVyOVokeqhUKikejzcdo1sX/Y4uxRBKzU/pFStfoVt+eYsufsnFSicnd5U8+OSDuvexe/WW4RlWGAUiiC4ff9GtC0xGC1dInXzEyTrleafo8z/5vH6161djK9Dv279Pd2y/Q/+19b908UsuVmp+yueSAug3dOsCk9HCFVLGGGVXZHXE4iP0na3f0bd+/S2l5qe0e+9urTx0pdb9/jotSizyu5gA+hAz+cItqjNM/UbgCrmVh67Ulf/nSu3eu1t7q3u1ZMESLYgv8LtYAPoc3brhFPUZpn6iSzEilixYoqMOOYqwBQCYNWaYeofABQAAJDHD1EsELgAAIIm9Ir1E4AIAAJKYYeolBs0DAABJzDD1EoELAACMYYapN+hSBAAA8BiBCwAAwGN0KQLoKlapBoDJCFwAuoZVqgGgNboUAXQNq1QDQGsELgBdwyrVANBaIAOXMWaNMWbD6Oio30UB0AFWqQaA1gIZuKy1G6216wYHB/0uCoAOsEo1ALTGoHkAXcMq1QDQGoELQFexSjUATBbILkUAAIAoIXABAAB4jMAFAADgMQIXAACAxwhcAAAAHiNwAQAAeIxlIQB0TbFYZA0uAGiBwAWgK4rFovL5vGKxmJLJpMrlsvL5vCQRugD0PboUAXRFoVBQLBZTIpGQMUaJREKxWEyFQsHvogGA7whcALqiVCopHo83HYvH4yqVSj6VCACCg8AFoCvS6bSq1WrTsWq1qnQ67VOJACA4CFwAuiKbzapWq8lxHFlr5TiOarWastms30UDAN8xaB5AVzQGxjNLEQAmI3AB6JpMJkPAAuaApVWii8AFAEAAsLRKtDGGCwCAAGBplWgjcAEAEAAsrRJtdCkCAOCDieO1EomEqtWqEonE2DksrRIdBC4AAHqs1XitSqUydn88Hle1WmVplQghcAEA0GPjx2tJGvt/3rx5WrBgAbMUI4jAFVBMDQaAmRWLRd11110aHR3VkiVLQvNeWSqVlEwmm47F43FVKhW95S1v8alU8BKBK4CYGgwAM2u8V0oK3XtlOp1WuVxmvFYfYZZiADE1GABmFub3SrbC6j+0cAXQVE3NTA0GgIMa75XW2rFjYXmvZCus/kPgCiCamgFgZo33ynnzDv4p8/q9spvja9kKq7/QpRhANDUDwMx6/V7ZGDNWLpebxowVi0VPng/RQgtXANHUDAAza7wn9mqWYqulHBzHUaFQ4P0ZMyJwBRRNzcDMWD4FmUxGK1askKRJY1+7jfG1mAu6FAGEEt076LV0Oq1qtdp0jPG1aBeBC0AohXlJAIQT42sxF3QpAgglunfQa4yvxVwQuACEEsunhE8UxtwxvhazRZcigFCieydcGHOHfkfgAhBKmUxGuVxOqVRKlUpFqVRKuVyO1oeAYswd+h1digBCi+6d8GDMHfodgQsA6qIwxiioGHOHfkeXIgCIMUZeY8wd+h2BCwDEGCOvMeYO/Y4uRQAQY4x6gTF36Ge0cAGA2LYFgLcIXAAgxhgB8BZdigAgtm0B4C0CFwDUMcYIgFd61qVojHmhMeazxpivG2Ou7NXzAgAA+K2twGWMud4Y84Qx5hcTjr/SGPMrY8xWY8y7p3sMa+2D1tq3SHqdpOHZFxkAACBc2u1S/HdJ10m6oXHAGDMg6V8lrZa0U9I9xpjbJA1IunbC97/RWvuEMebVkt5df6wZWWtVqVTaLOJBnXxPUslZPQdaoy79Q937i/r3D3Xvn7DUfRD+1rcVuKy1PzTGHDvh8GmStlprt0uSMeYmSa+x1l4r6bwpHuc2SbcZY74t6autzjHGrJO0TpJWrFjRTvEAAAACbS6D5o+S9Oi42zslnT7VycaYl0r6U0nzJd0+1XnW2g2SNkjS8PCwnbgQYSfa+d6KKm2dh85Qp/6h7v1F/fuHuvdP0Os+CH/r5xK4TItjdqqTrbV3SrpzDs8HAAAQSnOZpbhT0vg+v6MlPTa34gAAAETPXALXPZIyxpjjjDEJSRdIuq07xQIAAIiOdpeFuFHS/0h6gTFmpzHmTdba/ZLeLuk7kh6UdLO19gHvigoAABBO7c5SvHCK47drmgHwAAAAYPNqAAAAzwUycBlj1hhjNoyOjvpdFAAAgDkLZOCy1m601q4bHBz0uygAAABzFsjABQAAECUELgAAAI8RuAAAADxG4AIAAPAYgQsAAMBjBC4AAACPEbgAAAA8FsjAxcKnAAAgSgIZuFj4FAAARM8K0LsAABCKSURBVElbm1cDAID+ViwWVSgUVCqVlE6nlc1mtWLFCr+LFRoELgCB1OrNPZPJ+F0soC8Vi0Xl83nFYjElk0mVy2Xl83m9/OUv16pVq/wuXigQuAAEzlRv7pIIXSFCaI6OQqGgWCymRCIhSUokEnIcR5s3byZwtYnAFVC8UaGfTfXmXigU+D0ICUJztJRKJSWTyaZj8XhcTG5rXyAHzfe7xhtVuVxueqMqFot+Fw3oiVKppHg83nQsHo+rVCr5VCJ0anxoNsYokUgoFoupUCj4XTTMQjqdVrVabTpWrVbF5Lb20cIVQHy6x2xt27ZNW7ZsCX3LaDqdVrlcHvsdkNw393Q67WOp0ImpWkQaoZlW/HDJZrPK5/NyHEfxeFzValW1Wk2nn36630ULDVq4AohP95iNbdu2adOmTZFoGc1ms6rVanIcR9ZaOY6jWq2mbDbrd9HQpqlaRNLpNK34IZTJZJTL5ZRKpVSpVJRKpZTL5Ri/1YFAtnAZY9ZIWjM0NOR3UXzBp3vMxubNmyPTMtooLy0g4TVVi0g2m6UVP6Qymcykn0+lUvGpNOETyMBlrd0oaePw8PAVfpfFD9O9UQFTGR0dnbYLJ2xavbkjPKYLzbfffnukrlWgHYEMXP2OT/eYjcHBQe3Zs0cDAwNjx2gZhZ+mCs204qMfEbgCik/36NTpp5+uTZs20TKKwKMVv7uYgBAOBC4gIhqDV6MwSxHRRit+97DeWXgQuIAIWbVqlU444QS/iwHMiFb87mACQngQuAAACKnGRIOnnnpKBw4c0MDAgBYuXMgEhAAicAUUffIAgJkkEgnt2rVLxhgZY3TgwAE988wzWrZsmd9FwwQErgCiTx79hg8YwOwYYzo6Dv+w0nwAsQcZ+gmrjgOzt2/fPg0ODmpgYEDWWg0MDGhwcFD79u3zu2iYgMAVQGztg37CBwxg9tLptGKxmJYuXarly5dr6dKlisVirGkWQIEMXMaYNcaYDaOjo34XxRfT7UEGRA0fMIDZY9/R8AjkGC629mFRQPQPVh1HA2P5OseaZuERyMDV7/gFQj/hAwYkJgvNBWuahQOBK6D4BUK/4AMGJBbwRPQRuAB0rNtdP3zAQKlUUjKZbDrGWD5ESSAHzQMILpZxgBeYLISoI3AB6AjLOMALzLZD1PV1l2LjE/n69esZNwK0ia6f/tKrmYOM5UPU9W3ganSLSGJGDNABlnHoH72eOchYPkRZ33YpNrpFJNEt4rFisaiRkRGtX79eIyMjjPUJObp++gfdx0D39G0LF90ivcHaOtFD10//4H0S6J6+DVyNbpHx6BbpPtbWiSa6fvoD3cdA9/Rtl2KjW0QS3SIeYp88ILzoPga6p29buBqfzq/66lWqVCp0i3iET8jhwl52GI/uY6B7Ahm4jDFrJK0ZGhry9HnGQtdVV3n6PP2MffLCg/F2aIXuY6A7AtmlaK3daK1dNzg46HdRMEeZTEa5XE6pVEqVSkWpVEq5XI438ABiRhoAeCeQLVyIFj4hhwMz0gDAO4Fs4QLQe+xlBwDeoYWrQwwq7hx1Fg6MtwMA7xC4OsCg4s5RZ+HBjDQA8A6BqwMs4tk56ixcGG8HRA+9DMFA4OoAg4o7R50BgH/oZQgOBs13gEHFnaPOAMA/LPcSHASuDrDNReeoMwDwD9urBQddih1gUHHnqDMA8A/bqwUHgatDDCruHHUGAP5guZfgIHABABBR9DIEB4ELAIAIo5chGBg0DwAA4DECFwAAgMcCGbiMMWuMMRtGR0f9LgoAAMCcBTJwWWs3WmvXDQ4O+l0UAACAOQtk4AIAAIgSZikCQB9gA2PAXwQudEXjzXz37t0aHBzUmWeeyZs5EBC92MCYQAdMjy5FzFnjzbxcLiuZTGrPnj3K5/MqFot+Fw2AvN/AeOJ7QCPQ8R4AHETgwpyxGz0QbF5vYMx7ADAzuhQxZ6VSSclksukYu9EHF10//cfrDYx5DwBmRgsX5iydTqtarTYdYzf6YKLrpz9ls1nVajU5jiNrrRzH6eoGxrwHADMjcGHOvH4zR/fQ9dOfMpmMcrmcUqmUKpWKUqmUcrlc11o2eQ8AZkaXIuZs/G70zFIMlondh08++aRSqVTTOXT99AcvNzAe/x5AVzXQGoELXdF4M69UKpI0aTwHeq/VUgD79u3TwMCAFi1aNHYeXT/oBi8DHRAFBK4QY/AzpjO++1CSEomEksmknnvuOcXjccXjcVWrVbp+AKAHCFwh1YuFDBFurWaOLV68WLVaTalUKhRBnQ8VAKKCwBVSrVovHMdRoVDgDxIkTb0UwPLly7V27VofS9YePlQAiBJmKYaU1wsZIvzCPnOMGZUAooQWrpDyeiFDhF/YZ46xmCaAKCFwhVQ2m1U+n5fjOAx+xpTCPHOMDxUAooQuxZDyeiFDwG9h7xIFgPFo4QqxMLdeADMJe5coAIxH4AIQWHyoABAVgexSNMasMcZsGB0d9bsoAAAAcxbIwGWt3WitXTc4OOh3UQAAAOYskIELAAAgSghcAAAAHiNwAQAAeIzABQAA4DECFwAAgMcIXAAAAB5j4VMAHSsWi6wADwAdIHAB6EixWFQ+n1csFlMymVS5XFY+n5ckQhcATIEuRQAdKRQKisViSiQSMsYokUgoFoupUCj4XTQACCwCF4COlEolxePxpmPxeFylUsmnEgFA8BG4AHQknU6rWq02HatWq0qn0z6VCACCjzFcADqSzWaVz+flOI7i8biq1apqtZqy2azfResKJgQA8AKBC0BHGuEjiqGECQEAvELgAtCxTCYTyQAyfkKAJCUSCTmOo0KhEMnXC6B3GMMFAHVMCADgFQIXANQxIQCAVwhcAFCXzWZVq9XkOI6stXIcJ1ITAgD4hzFcAFAX5QkB8B8zYPsbgQsAxonqhAD4ixmwoEsRAACPsSUWCFwAAHiMGbAgcAEA4DFmwILABQCAx5gBCwbNAwDgMWbAgsAFAEAPMAO2v9GlCAAA4DECFwAAgMcC2aVojFkjac3Q0JDfRUGIsIozACCoAtnCZa3daK1dNzg46HdREBKNVZzL5XLTKs7FYtHvogEAEMzABXSKVZwBAEEWyC5FoFOlUknJZLLpGKs4o1/QnQ4EHy1ciARWcUa/ojsdCAdauFrg02L4ZLNZ5fN5OY6jeDyuarXKKs7oC+O70yUpkUjIcRwVCgXet4AAIXBN0Pi0GIvFmj4tSuLNK8BYxRn9iu50IBwIXBPwaTG8WMUZ/SidTqtcLo+9Z0l0pwNBxBiuCUqlkuLxeNMxPi0CCCo2RQbCgRauCfi0CCBM6E4HwoHANQGDrwGEDd3pQPARuCbg0yIAAOg2AlcLfFoEAADdROACECisg4cw4DpFpwhcAAKDdfAQBlynmA2WhQAQGGxCjjDgOsVs9H0L1zGDx8hcY/wuRmQk5a54XVHF55L0n0jX/VPS5ddc7ncpphXp+g+4wNR9CK7TbgtM3c/gmMFj/C4CgWvHO3b4XYRIqVTcX7qJW41gdsZ3XYxfpiSXy03quohC3Y+MjExaB89xHKVSKa1du9bHks0sCvUfVr2u+zBfp93Gdd8+uhSBAOu3rgtWTUcYcJ1iNvq+hQsIsn7bmJh18BAGXKeYDQIXEGD9uNUU6+AhDLhO0Sm6FIEAo+sCAKKBFi4gwOi6AIBoIHABAUfXBQCEH12KAAAAHiNwAQAAeIzABQAA4DECFwAAgMcYND8HxWKR2WMAAGBGBK5ZGr/HXTKZVLlcVj6flyRCFwAAaELgmqXxe9xJUiKRkOM4KhQKMwauKLaMNV7T7t27NTg4qDPPPDP0rwkAgG4hcM3SbPe4i2LL2MTXtGfPntC/JgAAuslYa/0uw5SMMU9KemSW375M0q4uFqf5wZctOz4Wi8WttbXGMWNMrFarVXft2vXrbn9fkE18TXv37p23cOHCWphfU4h5et1jRtS/f6h7/1D3Bx1jrT2s1R2BDlxzYYzZYq0d9rsc/Yi69w917y/q3z/UvX+o+/awLAQAAIDHCFwAAAAei3Lg2uB3AfoYde8f6t5f1L9/qHv/UPdtiOwYLgAAgKCIcgsXAABAIEQucBljXmmM+ZUxZqsx5t1+lydqjDErjDHfN8Y8aIx5wBhzVf34EmPMJmNMsf7/ofXjxhjzyfrP435jzKn+voLwM8YMGGPuM8Z8q377OGPM5nrdf80Yk6gfn1+/vbV+/7F+ljsKjDFpY8zXjTEP1X8H/oBrvzeMMX9df8/5hTHmRmNMkmvfO8aY640xTxhjfjHuWMfXujFmbf38ojFmrR+vJSgiFbiMMQOS/lVSTtKLJF1ojHmRv6WKnP2S3mmtfaGkMyS9rV7H75Z0h7U2I+mO+m3J/Vlk6v/WSfpM74scOVdJenDc7Q9J+ni97p+W9Kb68TdJetpaOyTp4/XzMDfrJf2Xtfb3JJ0k9+fAte8xY8xRkv5K0rC19kRJA5IuENe+l/5d0isnHOvoWjfGLJF0taTTJZ0m6epGSOtHkQpccn+gW6212621jqSbJL3G5zJFirX2d9ban9S/Lsv9g3OU3HoeqZ82Iun8+tevkXSDdd0tKW2MeV6Pix0ZxpijJb1K0ufrt42ksyV9vX7KxLpv/Ey+Lunl9fMxC8aYQySdJekLkmStday1JXHt98o8SQuMMfMkLZT0O3Hte8Za+0NJuycc7vRa/2NJm6y1u621T0vapMkhrm9ELXAdJenRcbd31o/BA/Vm+lMkbZZ0uLX2d5IbyiQtr5/Gz6S7PiHp7yQ1dipYKqlkrd1fvz2+fsfqvn7/aP18zM5KSU9K+mK9S/fzxphF4tr3nLX2t5I+Kuk3coPWqKR7xbXfa51e6/wOjBO1wNXqEwzTMD1gjFks6RZJ77DWPjPdqS2O8TOZBWPMeZKesNbeO/5wi1NtG/ehc/MknSrpM9baUyQ9q4NdKq1Q/11S74Z6jaTjJB0paZHcbqyJuPb9MVV983MYJ2qBa6ekFeNuHy3pMZ/KElnGmLjcsPUVa+036of/t9FdUv//ifpxfibd838lvdoYs0Nud/nZclu80vVuFqm5fsfqvn7/oCZ3EaB9OyXttNZurt/+utwAxrXvvVdIetha+6S1tirpG5Ky4trvtU6vdX4Hxola4LpHUqY+cyUhd1DlbT6XKVLq4yC+IOlBa+3Hxt11m6TGDJS1km4dd/yy+iyWMySNNpqk0Rlr7XustUdba4+Ve23/t7X2Yknfl/Ta+mkT677xM3lt/fy+/XQ5V9baxyU9aox5Qf3QyyX9Ulz7vfAbSWcYYxbW34Madc+131udXuvfkXSOMebQeivlOfVjfSlyC58aY86V+6l/QNL11tp/9rlIkWKM+UNJd0n6uQ6OI3qv3HFcN0t6vtw3xz+31u6uvzleJ3eg5HOS3mCt3dLzgkeMMealkt5lrT3PGLNSbovXEkn3SbrEWrvPGJOU9CW54+x2S7rAWrvdrzJHgTHmZLkTFhKStkt6g9wPrlz7HjPGXCPp9XJnSt8n6c1yxwNx7XvAGHOjpJdKWibpf+XONvxPdXitG2PeKPdvhCT9s7X2i718HUESucAFAAAQNFHrUgQAAAgcAhcAAIDHCFwAAAAeI3ABAAB4jMAFAADgMQIXAACAxwhcAAAAHiNwAQAAeOz/A408pn1Ju89AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Coarse Random Search\n",
    "lr_rng_coarse = [-4,-1]\n",
    "mbs_rng_coarse = [16,1024]\n",
    "\n",
    "param1_coarse = {\"hParam type\": \"learning_rate\" ,\n",
    "          \"hParam range\": lr_rng_coarse }\n",
    "    \n",
    "param2_coarse = {\"hParam type\": \"minibatch_size\",\n",
    "          \"hParam range\": mbs_rng_coarse } \n",
    "    \n",
    "lr_rng_fine, mbs_rng_fine, best_comb = random_search_2D(param1 = param1_coarse, param2 = param2_coarse , search_type =\"coarse\", evaluate_metric = \"accuracy\", sample_size = 100, search_summary = True, search_visualization = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fine Random Search\n",
    "\n",
    "param1_fine = {\"hParam type\": \"learning_rate\" ,\n",
    "          \"hParam range\": lr_rng_fine }\n",
    "    \n",
    "param2_fine = {\"hParam type\": \"minibatch_size\",\n",
    "          \"hParam range\": mbs_rng_fine } \n",
    "    \n",
    "lr_rng_detail, mbs_rng_detail, best_comb = random_search_2D(param1 = param1_fine, param2 = param2_fine , search_type =\"fine\", evaluate_metric = \"val_acc\", sample_size = 100, summary = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Detail Random Search\n",
    "\n",
    "param1_detail = {\"hParam type\": \"learning_rate\" ,\n",
    "          \"hParam range\": lr_rng_detail }\n",
    "    \n",
    "param2_detail = {\"hParam type\": \"minibatch_size\",\n",
    "          \"hParam range\": mbs_rng_detail } \n",
    "    \n",
    "lr_rng_fine, mbs_rng_fine, best_comb = random_search_2D(param1 = param1_detail, param2 = param2_detail , search_type =\"detail\", evaluate_metric = \"val_acc\", sample_size = 50, summary = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)\n",
    "print(np.where(score == np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = plt.imshow(score,cmap=\"RdYlGn\") #RdYlGn, PiYG, Accent,Blues,viridis, YlGnBu\n",
    "fig.colorbar(im,ax=ax,fraction=0.045)\n",
    "\n",
    "m = len(lr)\n",
    "n = len(mbz)\n",
    "    \n",
    "ax.set_title(\"Result of Grid Search\",fontsize=24,pad = 20)\n",
    "ax.set_xticks(range(0,m))\n",
    "ax.set_yticks(range(0,n))\n",
    "ax.set_xlabel(\"Learning Rate\", fontsize = 20)\n",
    "ax.set_ylabel(\"Minibatch Size\", fontsize = 20)\n",
    "\n",
    "ax.set_xticklabels(lr,fontsize=16,rotation=45)\n",
    "ax.set_yticklabels(mbz,fontsize=16)\n",
    "\n",
    "#setting horizontal axes labeling to top.\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "\n",
    "# Turn off all the ticks\n",
    "ax.tick_params(top=False,left=False)\n",
    "\n",
    "\n",
    "thres = [0.88, 0.96]\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        ax.text(j, i, \"%.4f\"%(score[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\" if score[i,j] > thres[1] or score[i,j] < thres[0]  else \"black\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(train_y_sample,prediction_train)\n",
    "\n",
    "cm_dev = confusion_matrix(dev_y_sample,prediction_dev)\n",
    "\n",
    "cm_test = confusion_matrix(test_y_sample,prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, macro_metrics, acc = model_metrics(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(file_name = \"hyperParameters\", parameters = hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_hyper_params = load_model(file_name = \"final_model_adam_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in loaded_hyper_params.items():\n",
    "    print(key + \": \" + str(value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
