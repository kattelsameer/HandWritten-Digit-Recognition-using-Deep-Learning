{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Notebook display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    .container#notebook-container    { width: 95%;}\n",
    "    div#menubar-container     { width: 95%; }\n",
    "    div#maintoolbar-container { width: 95%; }\n",
    "</style>\n",
    "<script>\n",
    "    document.getElementById(\"notebook-container\").style.margin = \"auto\";\n",
    "</script>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For running the notebook as Google Colab Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mounting the google drive for accessing other necessary files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Checking the available files in the \"Colab Notebooks\" folder of the google drive\n",
    "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks\n",
    "\n",
    "import sys\n",
    "\n",
    "#changing the current working directory to \"Colab Notebooks\" folder in the google drive\n",
    "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For running the notebook as Kaggle Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change directory to the dataset where our custom scripts are uploaded\n",
    "\n",
    "> ``os.chdir(\"/kaggle/input/handwritten-digit-recognition\")``\n",
    "\n",
    "***handwritten-digit-recognition*** is simply a folder name. It can vary based on the dataset you create in kaggle while uploading the python scripts.\n",
    "\n",
    "\n",
    "load custom module or files or dataset\n",
    "\n",
    "> ``from  dataset import load_dataset, train_dev_split, prep_dataset`` <br>\n",
    "> ```from dataset import visualize_data_distribution, visualize_dataset```\n",
    "\n",
    "\n",
    "reset our working directory\n",
    "\n",
    "> ```os.chdir(\"/kaggle/working/\")```\n",
    "\n",
    "**NOTE:** The ***input directory*** is Read-Only. So, we must switch back to the ***working directory*** for performing any other operation that requires write access. Make sure this note book runs as a part of the dataset you create as said above because all the custom modules are uploaded there. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time    #for calculating time\n",
    "import os\n",
    "#core packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os.chdir(\"/kaggle/input/handwritten-digit-recognition\")\n",
    "\n",
    "#custom module\n",
    "from dataset import load_dataset, train_dev_split, prep_dataset\n",
    "from dataset import visualize_data_distribution, visualize_dataset\n",
    "\n",
    "from ModelUtils import relu, relu_grad, softmax\n",
    "from ModelUtils import rand_mini_batches, convert_time\n",
    "from ModelUtils import confusion_matrix, plot_confusion_matrix, model_metrics, metric_summary\n",
    "from ModelUtils import visualize_training_results, visualize_prediction, visualize_mislabelled_images\n",
    "from ModelUtils import save_model, load_model\n",
    "\n",
    "from dataAugmentation import data_generator\n",
    "\n",
    "from ffnn import *\n",
    "\n",
    "\n",
    "# np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size_in_per = 100\n",
    "\n",
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig = load_dataset(dataset = \"mnist\", size_in_per = dataset_size_in_per)\n",
    "\n",
    "print(\"Sample Size : %d%%\\n\"%(dataset_size_in_per))\n",
    "print(\"Data\\t\\t\\t\",\"Datatype\\t\\t\",\"Dataset Size\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(type(train_x_orig))+\"\\t\",str(train_x_orig.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(type(train_y_orig))+\"\\t\",str(train_y_orig.shape))\n",
    "print(\"Test Set Images:\\t\" + str(type(test_x_orig))+\"\\t\",str(test_x_orig.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(type(test_y_orig))+\"\\t\",str(test_y_orig.shape))\n",
    "print(\"=================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Dev set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_split, train_y_split, dev_x_split, dev_y_split = train_dev_split(train_x_orig, train_y_orig)\n",
    "\n",
    "print(\"Data\\t\\t\\t\\t\",\"Datatype\\t\\t\",\"Shape\")\n",
    "print(\"========================================================================\")\n",
    "print(\"Training Set Images:\\t\\t\" + str(type(train_x_split))+\"\\t\",str(train_x_split.shape))\n",
    "print(\"Training Set Labels:\\t\\t\" + str(type(train_y_split))+\"\\t\",str(train_y_split.shape))\n",
    "print(\"Development Set Images:\\t\\t\" + str(type(dev_x_split))+\"\\t\",str(dev_x_split.shape))\n",
    "print(\"Development Set Labels:\\t\\t\" + str(type(dev_y_split))+\"\\t\",str(dev_y_split.shape))\n",
    "print(\"========================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_distribution(train_y_split, dataset_type = \"training\")\n",
    "visualize_data_distribution(dev_y_split,  dataset_type = \"dev\")\n",
    "visualize_data_distribution(test_y_orig,  dataset_type = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(train_x_split, train_y_split, dataset = \"mnist\", dataset_type = \"training\")\n",
    "visualize_dataset(dev_x_split, dev_y_split, dataset = \"mnist\", dataset_type = \"dev\")\n",
    "visualize_dataset(test_x_orig, test_y_orig, dataset = \"mnist\", dataset_type=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocess training set will only be used later during prediction. The splitted training set will be directly fed to the model and it is preprocessed in the fly during the augmentation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_norm, train_y_encoded = prep_dataset(train_x_split, train_y_split, num_class = 10)\n",
    "dev_x_norm, dev_y_encoded= prep_dataset(dev_x_split, dev_y_split, num_class = 10)\n",
    "test_x_norm, test_y_encoded = prep_dataset(test_x_orig, test_y_orig, num_class = 10)\n",
    "\n",
    "print(\"Data\\t\\t\\t\",\"Before Processing\\t\",\"After Processing\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(train_x_split.shape)+\"\\t\\t\"+ str(train_x_norm.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(train_y_split.shape)+\"\\t\\t\"+ str(train_y_encoded.shape))\n",
    "print(\"Dev Set Images:\\t\\t\" + str(dev_x_split.shape)+\"\\t\\t\"+ str(dev_x_norm.shape))\n",
    "print(\"Dev Set Labels:\\t\\t\" + str(dev_y_split.shape)+\"\\t\\t\"+ str(dev_y_encoded.shape))\n",
    "print(\"Test Set Images:\\t\" + str(test_x_orig.shape)+\"\\t\\t\"+ str(test_x_norm.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(test_y_orig.shape)+\"\\t\\t\"+ str(test_y_encoded.shape))\n",
    "print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Training\n",
    "\n",
    "def train(X_train, Y_train, X_dev, Y_dev, layers_dim, hyperParams, initialization = \"random\", optimizer = 'bgd',regularizer = None, verbose = 3, patience = None):\n",
    "    # loading the hyper parameters\n",
    "    learning_rate = hyperParams['learning_rate']\n",
    "    num_epoch = hyperParams['num_epoch']\n",
    "    b1 = hyperParams['beta1']\n",
    "    b2 = hyperParams['beta2']\n",
    "    ep = hyperParams['epsilon']\n",
    "    lambd = hyperParams['lambda']\n",
    "    keep_probs = hyperParams['keep_probs']\n",
    "\n",
    "    #setting up necessary variables for early stopping\n",
    "    if patience != None:\n",
    "        path = \"temp/\" # pats to save the intermediate best parameters\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        filename = \"best_param_intermediate\"\n",
    "\n",
    "        early_stop_count = 0 #for early stopping\n",
    "        max_val_acc = 0 # for keeping track of maximum validation accuracy\n",
    "    \n",
    "    #initializing the variables\n",
    "    seed = 1\n",
    "    m = Y_train.shape[1]\n",
    "    train_accs = []  # keep track of training accuracy\n",
    "    val_accs = []     # keep track of Validation accuracy\n",
    "    train_losses = []  # keep track of training loss\n",
    "    val_losses = []     # keep track of Validation loss\n",
    "    \n",
    "    #selecting the minibatch size for each optimizer\n",
    "    if optimizer == 'sgd':\n",
    "        mini_batch_size = 1\n",
    "    elif optimizer == 'bgd':\n",
    "        mini_batch_size = m\n",
    "    elif optimizer == 'mgd' or optimizer == 'adam':\n",
    "        mini_batch_size = hyperParams['mini_batch_size']\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer value out of scope\")\n",
    "        \n",
    "    #initializing the model parameters\n",
    "    parameters = init_parameters(layers_dim, initialization)\n",
    "    \n",
    "    #initializing adam parameters, used only when optimizer = 'adam'\n",
    "    t = 0\n",
    "    v,s = initialize_adam(parameters)\n",
    "    \n",
    "    train_toc = time.time() # for calculating entire training time\n",
    "    print(\"Training The Model...\")\n",
    "    \n",
    "    #Gradient Descent begins\n",
    "    for i in range(1, num_epoch+1):\n",
    "        seed += 1\n",
    "        time_trained = 0\n",
    "        batch_times = []\n",
    "        accs = []\n",
    "        losses = []\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(\"\\nEpoch %d/%d\"%(i,num_epoch))\n",
    "        \n",
    "        #augmenting dataset online\n",
    "        augmented_images, augmented_labels = data_generator(X_train, Y_train, batch_size = 2048, aug_count = 4, pre_process_data = True)\n",
    "        \n",
    "        minibatches = rand_mini_batches(augmented_images, augmented_labels, mini_batch_size, seed)\n",
    "        total_minibatches = len(minibatches)\n",
    "        \n",
    "        #clearing the memory of unused data because once the minibatches are created they have no use\n",
    "        augmented_images = augmented_labels = 0\n",
    "        \n",
    "        for ind, minibatch in enumerate(minibatches):\n",
    "            batch_toc = time.time() # for calculating time of an epoch cycle\n",
    "            \n",
    "            #retriving minibatch of X and Y from training set\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            \n",
    "            #forward Propagation\n",
    "            AL, caches, dropout_masks = forward_prop(minibatch_X, parameters, keep_probs = keep_probs, regularizer = regularizer)\n",
    "            \n",
    "            #Computing cross entropy cost\n",
    "            cross_entropy_cost = softmax_cross_entropy_cost(AL, minibatch_Y, caches, lambd = lambd, regularizer = regularizer, from_logits = True) #accumulating the batch costs\n",
    "            \n",
    "            #Backward Propagation\n",
    "            grads = backward_prop(AL, minibatch_Y, caches, dropout_masks = dropout_masks, keep_probs = keep_probs, lambd = lambd, regularizer = regularizer)\n",
    "                \n",
    "            #Updating parameters\n",
    "            t += 1\n",
    "            parameters, v, s = update_parameters(parameters, grads, learning_rate, optimizer = optimizer, beta1 = b1, beta2 = b2,  epsilon = ep, v = v, s = s, t = t)\n",
    "            \n",
    "            # Calculating training time for each batch \n",
    "            batch_tic = time.time()\n",
    "            batch_times.append(batch_tic - batch_toc)\n",
    "            time_trained = np.sum(batch_times)\n",
    "            \n",
    "            #calculating training progress\n",
    "            per = ((ind+1) / total_minibatches) * 100\n",
    "            inc = int(per // 10) * 2\n",
    "            \n",
    "            #calculating accuracy and loss of the training batch\n",
    "            acc,loss = evaluate(minibatch_X, minibatch_Y, parameters)\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            #averaging all the accs and losses till now\n",
    "            train_acc = np.mean(accs)\n",
    "            train_loss = np.mean(losses)\n",
    "            \n",
    "            #Verbosity 0: Silent mode\n",
    "            #Verbosity 1: Epoch mode\n",
    "            #Verbosity 2: Progress bar mode\n",
    "            #Verbosity 3 or greater: Metric mode\n",
    "                \n",
    "            if verbose == 2:\n",
    "                print (\"%d/%d [%s>%s %.0f%%] - %.2fs\"%(ind+1, total_minibatches, '=' * inc,'.'*(20-inc), per, time_trained),end='\\r')\n",
    "            elif verbose > 2:\n",
    "                print (\"%d/%d [%s>%s %.0f%%] - %.2fs | loss: %.4f | acc: %.4f\"%(ind+1, total_minibatches, '=' * inc,'.'*(20-inc), per, time_trained, train_loss, train_acc),end='\\r')\n",
    "            \n",
    "        #----------------------------------------------batch ends-------------------------------------------\n",
    "        #clearing the memory of unused data because once the minibatches are trained they have no use as new set of minibatches are created in each epoch\n",
    "        minibatches = 0\n",
    "        \n",
    "        #accumulating the acc and loss of the last iteration of each epoch\n",
    "        train_accs.append(np.mean(accs))\n",
    "        train_losses.append(np.mean(losses))\n",
    "                \n",
    "        #evaluating the model using validation accuracy and loss\n",
    "        val_acc, val_loss= evaluate(X_dev, Y_dev, parameters)  \n",
    "        val_accs.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "\n",
    "        time_per_batch = int(np.mean(batch_times)*1000)\n",
    "\n",
    "        if verbose == 2:\n",
    "            print (\"%d/%d [%s 100%%] - %.2fs %dms/step\"%(total_minibatches, total_minibatches, '=' * 20, time_trained, time_per_batch ),end='\\r')\n",
    "        elif verbose > 2:\n",
    "            print (\"%d/%d [%s 100%%] - %.2fs %dms/step | loss: %.4f | acc: %.4f | val_loss: %.4f | val_acc: %.4f\"%(total_minibatches, total_minibatches, '=' * 20, time_trained, time_per_batch, train_loss, train_acc, val_loss, val_acc),end='\\r')\n",
    "\n",
    "            \n",
    "            \n",
    "        if patience != None:\n",
    "            #getting the best val accuracy\n",
    "            if val_acc >= max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                print(\"\\nBetter validation accuracy found. So saving the corresponding parameters...\")\n",
    "                save_model(path+filename, parameters)\n",
    "\n",
    "            # Early Stopping\n",
    "            if patience >= 5:\n",
    "                epoch_trained = i+1\n",
    "\n",
    "                if val_acc < max_val_acc:\n",
    "                    early_stop_count += 1\n",
    "                else:\n",
    "                    early_stop_count = 0\n",
    "\n",
    "                if early_stop_count == patience:\n",
    "                    print(\"\\n\\nSince the Val Acc didn't increase for last %d epochs, Training is halted returning the best parameters obtained.\"%patience)\n",
    "                    break;\n",
    "    #-------------------------------------------Gradient Descent ends-----------------------------------------------\n",
    "    \n",
    "    train_tic = time.time() # for calculating entire training time\n",
    "    hrs, mins, secs , ms = convert_time((train_tic - train_toc)*1000)\n",
    "    print(\"\\n\\nTotal Training Time = %dhr %dmins %dsecs %.2fms\"%(hrs, mins, secs, ms))\n",
    "    \n",
    "    #loading the best parameters\n",
    "    if patience != None:\n",
    "        parameters = load_model(path+filename)\n",
    "        os.remove(path + filename) #removing temporary file\n",
    "    history = {\"parameters\":parameters,\n",
    "               \"accuracy\": train_accs,\n",
    "               \"loss\":train_losses ,\n",
    "               \"val_accuracy\":val_accs,\n",
    "               \"val_loss\":val_losses\n",
    "            }\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers_dim = init_layers(784, 10, hidden_layers = [2900])\n",
    "hyperParams = init_hyperParams(alpha = 0.001630, num_epoch = 100, minibatch_size = 262, keep_probs = [0.8])\n",
    "history = train(train_x_split, train_y_split, dev_x_norm, dev_y_encoded,layers_dim, hyperParams, initialization = \"he\", optimizer = 'adam',regularizer = \"dropout\", verbose = 3, patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = history[\"parameters\"]\n",
    "params = history[\"best_params\"]\n",
    "train_acc = history[\"accuracy\"]\n",
    "train_loss = history[\"loss\"]\n",
    "val_acc = history[\"val_accuracy\"]\n",
    "val_loss = history[\"val_loss\"]\n",
    "epochs = len(val_acc)\n",
    "\n",
    "\n",
    "visualize_training_results(train_acc, val_acc, train_loss, val_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Epochs\\t | Train Acc\\t | Train Loss\\t | Val Acc\\t | Val Loss\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "for i in range(epochs):\n",
    "    print(\" %d\\t | %f\\t | %f\\t | %f\\t | %f\"%(i+1,train_acc[i] ,train_loss[i],val_acc[i] ,val_loss[i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = predict(train_x_norm, params, second_guess = True)\n",
    "prediction_dev = predict(dev_x_norm,params, second_guess = True)\n",
    "prediction_test = predict(test_x_norm, params, second_guess = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(train_y_split, prediction_train)\n",
    "cm_dev = confusion_matrix(dev_y_split, prediction_dev)\n",
    "cm_test = confusion_matrix(test_y_orig, prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the confusion matrix   \n",
    "plot_confusion_matrix(cm_train, dataset_type = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_dev, dataset_type = \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_test, dataset_type = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, macro_metrics, acc = model_metrics(cm_train)\n",
    "metric_summary(metrics, macro_metrics, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, macro_metrics, acc = model_metrics(cm_dev)\n",
    "metric_summary(metrics, macro_metrics, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, macro_metrics, acc = model_metrics(cm_test)\n",
    "metric_summary(metrics, macro_metrics, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizating  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction(train_x_split, train_y_split.T, prediction_train, dataset_type = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction(dev_x_split, dev_y_split.T, prediction_dev, dataset_type = \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction(test_x_orig, test_y_orig.T, prediction_test,dataset_type = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Mislabelled Images in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mislabelled_images(train_x_split, train_y_split.T,prediction_train,dataset_type = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mislabelled_images(dev_x_split, dev_y_split.T, prediction_dev,dataset_type = \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mislabelled_images(test_x_orig, test_y_orig.T, prediction_test,dataset_type = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Real Time images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_name = \"8_1.jpg\" \n",
    "\n",
    "fname = \"Sample Images/\" + image_name\n",
    "\n",
    "image_data = np.asarray(Image.open(fname).convert('L').resize((28,28)))\n",
    "if image_data[1,1] > 250: #if background is white, reversing the fore and background color to match training images\n",
    "            image_data = 255 - image_data\n",
    "def predict_real_time(image_data, second_guess = True):\n",
    "    image_flattened = image_data.reshape(image_data.shape[0]*image_data.shape[1],-1)\n",
    "    image_norm =(image_flattened/255.)\n",
    "\n",
    "    prediction = predict(image_norm, params, second_guess = second_guess)\n",
    "    \n",
    "    return prediction\n",
    "    \n",
    "prediction = predict_real_time(image_data, second_guess = True)\n",
    "\n",
    "first_lbl, first_prob = prediction[\"First Prediction\"]\n",
    "sec_lbl, sec_prob = prediction[\"Second Prediction\"]\n",
    "\n",
    "# plt.title(\"True Label: \"+ str(label.squeeze()))\n",
    "plt.xlabel(\"Prediction: %d | With Prob: %.4f \\n2nd Guess: %d | With Prob: %.4f\"%(first_lbl, first_prob, sec_lbl, sec_prob), fontsize = 14)\n",
    "plt.imshow(image_data, interpolation ='nearest',cmap='gray')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "\n",
    "# d = date.today()\n",
    "\n",
    "path = \"Saved Models/\"\n",
    "fname = \"arch3_online_Augmented_model_200k_test_acc_\"+str(acc)\n",
    "\n",
    "print(fname)\n",
    "\n",
    "model = {\"Parameters\": params,\n",
    "         \"Activations\": [\"relu\",\"softmax\"],\n",
    "## Save the following info if needed\n",
    "         \"Hyper Parameters\": hyperParams,\n",
    "         \"initialization\":\"he\",\n",
    "         \"regularizer\":\"dropout\",\n",
    "         \"optimizer\":\"adam\"\n",
    "        }\n",
    "save_model(file_name = path+fname, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model\n",
    "path = \"Saved Models/\"\n",
    "\n",
    "model = load_model(file_name =path+ \"arch3_online_Augmented_model_200k_test_acc_0.986\")\n",
    "\n",
    "loaded_params = model[\"Parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(loaded_params) // 2\n",
    "print(\"Total Layers %d: \"%L)\n",
    "for l in range(L):\n",
    "    print(loaded_params[\"W\" + str(l+1)].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Optimize and refactor the code\n",
    "- [ ] Prepare the doc String\n",
    "- [x] add verbose: Integer. 0, 1, 2 or 3. Verbosity mode.\n",
    "- [ ] Batch norm\n",
    "- [ ] Maxout\n",
    "- [ ] Drop Connect\n",
    "- [x] Data Augmentation if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter-nbconvert --to html 'Project Modules Evaluation with online data augmentation.ipynb' --output Experiments/experiment-8/arch3-200k_.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
