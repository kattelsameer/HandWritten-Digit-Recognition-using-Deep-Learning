{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time    #for calculating time\n",
    "import math    #for using floor in creating minibatches\n",
    "import pickle  #for saving model\n",
    "\n",
    "\n",
    "#core packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#custom module\n",
    "from  dataset import load_dataset, train_dev_split, prep_dataset\n",
    "from dataset import visualize_data_distribution, visualize_dataset, label_description\n",
    "\n",
    "# from finalModelUtils import relu, relu_grad, softmax\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size : 100%\n",
      "\n",
      "Data\t\t\t Datatype\t\t Dataset Size\n",
      "=================================================================\n",
      "Training Set Images:\t<class 'numpy.ndarray'>\t (60000, 28, 28)\n",
      "Training Set Labels:\t<class 'numpy.ndarray'>\t (60000, 1)\n",
      "Test Set Images:\t<class 'numpy.ndarray'>\t (10000, 28, 28)\n",
      "Test Set Labels:\t<class 'numpy.ndarray'>\t (10000, 1)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "dataset_size_in_per = 100\n",
    "\n",
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig = load_dataset(dataset = \"mnist\", size_in_per = dataset_size_in_per)\n",
    "\n",
    "print(\"Sample Size : %d%%\\n\"%(dataset_size_in_per))\n",
    "print(\"Data\\t\\t\\t\",\"Datatype\\t\\t\",\"Dataset Size\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(type(train_x_orig))+\"\\t\",str(train_x_orig.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(type(train_y_orig))+\"\\t\",str(train_y_orig.shape))\n",
    "print(\"Test Set Images:\\t\" + str(type(test_x_orig))+\"\\t\",str(test_x_orig.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(type(test_y_orig))+\"\\t\",str(test_y_orig.shape))\n",
    "print(\"=================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Dev set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\t\t\t Datatype\t\t Shape\n",
      "========================================================================\n",
      "Training Set Images:\t\t<class 'numpy.ndarray'>\t (50000, 28, 28)\n",
      "Training Set Labels:\t\t<class 'numpy.ndarray'>\t (50000, 1)\n",
      "Development Set Images:\t\t<class 'numpy.ndarray'>\t (10000, 28, 28)\n",
      "Development Set Labels:\t\t<class 'numpy.ndarray'>\t (10000, 1)\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "train_x_split, train_y_split, dev_x_split, dev_y_split = train_dev_split(train_x_orig, train_y_orig)\n",
    "\n",
    "print(\"Data\\t\\t\\t\\t\",\"Datatype\\t\\t\",\"Shape\")\n",
    "print(\"========================================================================\")\n",
    "print(\"Training Set Images:\\t\\t\" + str(type(train_x_split))+\"\\t\",str(train_x_split.shape))\n",
    "print(\"Training Set Labels:\\t\\t\" + str(type(train_y_split))+\"\\t\",str(train_y_split.shape))\n",
    "print(\"Development Set Images:\\t\\t\" + str(type(dev_x_split))+\"\\t\",str(dev_x_split.shape))\n",
    "print(\"Development Set Labels:\\t\\t\" + str(type(dev_y_split))+\"\\t\",str(dev_y_split.shape))\n",
    "print(\"========================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\t\t Before Processing\t After Processing\n",
      "=================================================================\n",
      "Training Set Images:\t(50000, 28, 28)\t\t(784, 50000)\n",
      "Training Set Labels:\t(50000, 1)\t\t(10, 50000)\n",
      "Dev Set Images:\t\t(10000, 28, 28)\t\t(784, 10000)\n",
      "Dev Set Labels:\t\t(10000, 1)\t\t(10, 10000)\n",
      "Test Set Images:\t(10000, 28, 28)\t\t(784, 10000)\n",
      "Test Set Labels:\t(10000, 1)\t\t(10, 10000)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "train_x_norm, train_y_encoded = prep_dataset(train_x_split, train_y_split, num_class = 10)\n",
    "dev_x_norm, dev_y_encoded= prep_dataset(dev_x_split, dev_y_split, num_class = 10)\n",
    "test_x_norm, test_y_encoded = prep_dataset(test_x_orig, test_y_orig, num_class = 10)\n",
    "\n",
    "print(\"Data\\t\\t\\t\",\"Before Processing\\t\",\"After Processing\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(train_x_split.shape)+\"\\t\\t\"+ str(train_x_norm.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(train_y_split.shape)+\"\\t\\t\"+ str(train_y_encoded.shape))\n",
    "print(\"Dev Set Images:\\t\\t\" + str(dev_x_split.shape)+\"\\t\\t\"+ str(dev_x_norm.shape))\n",
    "print(\"Dev Set Labels:\\t\\t\" + str(dev_y_split.shape)+\"\\t\\t\"+ str(dev_y_encoded.shape))\n",
    "print(\"Test Set Images:\\t\" + str(test_x_orig.shape)+\"\\t\\t\"+ str(test_x_norm.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(test_y_orig.shape)+\"\\t\\t\"+ str(test_y_encoded.shape))\n",
    "print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relu function\n",
    "def relu(Z):\n",
    "    \"\"\"Compute the ReLU activation of Z.\n",
    "        \n",
    "        Arguments:\n",
    "            Z (numpy.ndarray): Input Sum to a hidden unit, Z = W * X + b.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Following values\n",
    "            - **A** (numpy.ndarray): Activation obtained by applying ReLU function to the sum. Size same as that of Z.\n",
    "            - **cache** (numpy.ndarray): Value stored for use during backward propagation.\n",
    "        \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> Z = np.random.randn(1,6)\n",
    "            >>> **A,cache = relu(Z)**\n",
    "            >>> print(A)\n",
    "            \n",
    "            Output: \n",
    "                [[1.62434536 0.     0.      0.      0.86540763 0.    ]]\n",
    "    \"\"\"\n",
    "\n",
    "    A = np.maximum(0.0,Z)\n",
    "    \n",
    "    cache = Z #storing Z for later use during back propagation\n",
    "    assert(A.shape == Z.shape)\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relu gradient function\n",
    "def relu_grad(dA, cache):\n",
    "    \"\"\"Compute the backward ReLU activation of dA.\n",
    "        \n",
    "        Arguments:\n",
    "            dA (numpy.ndarray): Gradient of activation of the previous layer.\n",
    "            cache (numpy.ndarray): Value of Z stored during forward prop.\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: - **dZ**: array of gradient/derivative of the dA, Same size of dA.\n",
    "            \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> dA = np.random.randn(1,6)\n",
    "            >>> cache = np.random.randn(1,6)\n",
    "            >>> **dZ = relu_grad(dA,cache)**\n",
    "            >>> print(dZ)\n",
    "            \n",
    "            Output:\n",
    "                [[ 1.62434536  0.         -0.52817175  0.          0.86540763  0.        ]]\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    \n",
    "    dZ[Z <= 0] = 0 #implementing integrated form of (gradiant of ReLU function * gradient of the loss function)\n",
    "    \n",
    "    assert(dZ.shape == Z.shape)\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"Compute the softmax activtion of Z.\n",
    "        \n",
    "        Argument:\n",
    "            Z (numpy.ndarray): Input Sum to a hidden unit, Z = W * X + b.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Following Values\n",
    "            - **A** (numpy.ndarray): Activation obtained by applying softmax function to the sum. Size same as that of Z.\n",
    "            - **cache** (numpy.ndarray): Value stored for use during backward propagation.\n",
    "            \n",
    "        Example:\n",
    "            >>> np.random.seed(2)\n",
    "            >>> Z= np.random.rand(7,1)\n",
    "            >>> **A,cache = softmax(Z)**\n",
    "            >>> print(A)\n",
    "            \n",
    "            Output:\n",
    "                [[0.15477477]\n",
    "                 [0.10270926]\n",
    "                 [0.17340649]\n",
    "                 [0.15467071]\n",
    "                 [0.15237489]\n",
    "                 [0.13925557]\n",
    "                 [0.12280831]]\n",
    "    \"\"\"\n",
    "    shift = Z - np.max(Z, axis = 0) #Avoiding underflow or overflow errors due to floating point instability in softmax\n",
    "    t = np.exp(shift)\n",
    "    A = np.divide(t,np.sum(t,axis = 0))\n",
    "    \n",
    "    cache = Z\n",
    "    assert(A.shape == Z.shape)\n",
    "    return A, cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing \n",
    "```\n",
    "z = np.asarray([[1,2,3,6],[2,4,5,6],[1,2,3,6]],dtype='float32')\n",
    "z = z.T\n",
    "print(z)\n",
    "a,c = softmax(z)\n",
    "print(a)\n",
    "print(np.sum(a, axis = 0),end = '\\n\\n\\n\\n')\n",
    "\n",
    "print(\"-\"*40)\n",
    "#ref link https://exceptionshub.com/how-to-implement-the-softmax-function-in-python.html\n",
    "\n",
    "z = np.asarray([[1,2,3,6],[2,4,5,6],[1,2,3,6]],dtype='float32')\n",
    "print(z)\n",
    "s = np.max(z, axis=1).reshape((-1, 1))\n",
    "print(s)\n",
    "e_x = np.exp(z - s)\n",
    "print(e_x)\n",
    "div = np.sum(e_x, axis=1).reshape((-1, 1))\n",
    "print(div)\n",
    "a =  e_x / div\n",
    "\n",
    "print(a)\n",
    "print(np.sum(a, axis = 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "z = np.asarray([[1,2,3,6],[2,4,5,6],[1,2,3,6]],dtype='float32')\n",
    "print(z, z.shape)\n",
    "print(z.T, z.T.shape)\n",
    "\n",
    "batch = tf.constant(z)\n",
    "print(batch)\n",
    "y = tf.nn.softmax(batch)\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(batch))\n",
    "# Find the index of the largest value\n",
    "print(tf.argmax(batch))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(batch))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.utils.extmath import softmax\n",
    "import numpy as np\n",
    "z = np.asarray([[1,2,3,6],[2,4,5,6],[1,2,3,6]],dtype='float32').reshape(3,4)\n",
    "\n",
    "softmax(z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_mini_batches(X, Y, minibatch_size = 64, seed=1):\n",
    "    \"\"\"Returns the minibatches of X and corresponding Y of the given size.\n",
    "    \n",
    "        Arguments:\n",
    "            X (numpy.ndarray): Inputs Array.\n",
    "            Y (numpy.ndarray): Output Labels.\n",
    "            minibatch_size (int): Size of each minibatch.\n",
    "            seed (int): Seed value for randomness.\n",
    "        \n",
    "        Returns:\n",
    "            list: - **minibatches**: List of minibatches where each minibatch contains a minibatch of X and a minibatch of its corresponding Y.\n",
    "            \n",
    "        Examples:\n",
    "            >>> X = np.random.randn(20,20)\n",
    "            >>> Y = np.random.rand(1,20)\n",
    "            >>> **minibatches = rand_mini_batches(X,Y,minibatch_size = 4, seed = 2)**\n",
    "            >>> print(minibatches[0][0].shape)\n",
    "            >>> print(minibatches[0][1].shape)\n",
    "            \n",
    "            Outputs:\n",
    "                (20, 4)\n",
    "                (1, 4)\n",
    "    \"\"\"\n",
    "   \n",
    "    classes = Y.shape[0]\n",
    "    np.random.seed(seed) # varying the seed value so that the minibatchs become random in each epoch\n",
    "    m = X.shape[1]       # number of training examples\n",
    "    minibatches = []\n",
    "        \n",
    "    #Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((classes,m))\n",
    "\n",
    "    #Partition (shuffled_X, shuffled_Y) except for the last batch\n",
    "    num_complete_minibatches = math.floor(m/minibatch_size) # number of mini batches of size minibatch_size \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        minibatch_X = shuffled_X[:, k * minibatch_size : (k+1)*minibatch_size]\n",
    "        minibatch_Y = shuffled_Y[:, k * minibatch_size : (k+1)*minibatch_size]\n",
    "        minibatch = (minibatch_X, minibatch_Y)\n",
    "        minibatches.append(minibatch)\n",
    "    \n",
    "    # Last batch (last minibatch <= minibatch_size)\n",
    "    if m % minibatch_size != 0:\n",
    "        minibatch_X = shuffled_X[:, num_complete_minibatches * minibatch_size : m]\n",
    "        minibatch_Y = shuffled_Y[:, num_complete_minibatches * minibatch_size : m]\n",
    "        minibatch = (minibatch_X, minibatch_Y)\n",
    "        minibatches.append(minibatch)\n",
    "    \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time Conversion\n",
    "def convert_time(millisec):\n",
    "    \"\"\"Converts time in miliseconf to higher values.\n",
    "    \n",
    "        Arguments:\n",
    "            milisec (int): Time in mili-seconds.\n",
    "        \n",
    "        Returns: \n",
    "            tuple: Following values\n",
    "            - **hours** (int):  Time in hours.\n",
    "            - **mins** (int): Time in minutes.\n",
    "            - **secs** (int):  Time in seconds.\n",
    "            - **milisec** (int): Time in mili-seconds.\n",
    "            \n",
    "        Example:\n",
    "            >>> **hr,mins,sec,milisec = convert_time(millisec = 12450)**\n",
    "            >>> print(\"%dhr %dmins %ds %dms\"%(hr,mins,sec,milisec))\n",
    "            \n",
    "            Outputs:\n",
    "                0hr 0mins 12s 450ms\n",
    "    \"\"\"\n",
    "    #converting millisecons to hours, minutes, seconds and millisecond\n",
    "    #the large numbers like 3.6e+6 comes from the relation between the time units\n",
    "    hours = millisec // 3.6e+6\n",
    "    mins = (millisec % 3.6e+6) // 60000\n",
    "    secs = ((millisec % 3.6e+6) % 60000) // 1000\n",
    "    millisec = ((millisec % 3.6e+6) % 60000) % 1000\n",
    "    \n",
    "    return (hours, mins, secs, millisec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing and Visualizing Evaluation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Confusion Matrix\n",
    "def confusion_matrix(y_orig,prediction):\n",
    "    \"\"\"Returns a confusion matrix for a given output labels and prediction.\n",
    "    \n",
    "        Arguments:\n",
    "            y_orig (numpy.ndarray): Original Output Labels of shape(m,1); m = # of examples.\n",
    "            prediction (numpy.ndarray): Predicted Labels of the dataset of shape (1,m).\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray:- **cm**: 2D confusion matrix.\n",
    "            \n",
    "        Example:\n",
    "            >>> y = np.array([[1,2,3,3,0,2,5,4,2,2]]).reshape(10,1)\n",
    "            >>> pred = np.array([[2,2,1,3,0,2,5,4,2,2]]).reshape(1,10)\n",
    "            >>> prediction = {\"First Prediction\":pred}\n",
    "            >>> **cm_train = confusion_matrix(y,prediction)**\n",
    "            >>> print(cm_train)\n",
    "            \n",
    "            Output:\n",
    "                [[1 0 0 0 0 0]\n",
    "                 [0 0 1 0 0 0]\n",
    "                 [0 0 4 0 0 0]\n",
    "                 [0 1 0 1 0 0]\n",
    "                 [0 0 0 0 1 0]\n",
    "                 [0 0 0 0 0 1]]\n",
    "    \"\"\"\n",
    "    first_predict = prediction[\"First Prediction\"]\n",
    "    \n",
    "    y_predicted = first_predict[0].T\n",
    "    \n",
    "    m = y_orig.shape[0]\n",
    "    classes = len(np.unique(y_orig)) # or simply take classes = 10 for mnist or fashion-mnist\n",
    "    \n",
    "    cm = np.zeros((classes,classes)) #creating the matrix frame for the confusion matrix\n",
    "    \n",
    "    # generating the values in the confusion metrix\n",
    "    for i in range(m):\n",
    "        cm[y_orig[i],y_predicted[i]] += 1\n",
    "   \n",
    "    return cm.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Confusion Matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, dataset_type, dataset = \"mnist\"):\n",
    "    \"\"\"Plots the Heatmap of the confusion matrix.\n",
    "    \n",
    "        Arguments:\n",
    "            cm (numpy.ndarray): 2D confusion matrix.\n",
    "            dataset_type (str): Type of dataset. May be training or dev or test.\n",
    "            dataset (str): Dataset used to train the model. Default to 'mnist'\n",
    "            \n",
    "        Example:\n",
    "            >>> plot_confusion_matrix(cm, dataset_type)\n",
    "    \"\"\"\n",
    "    # plotting the metrix\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    im = plt.imshow(cm,cmap=\"GnBu\") #RdYlGn, PiYG, Accent,Blues,viridis, YlGnBu\n",
    "    \n",
    "    # plotting the color bar of the plot size\n",
    "    fig.colorbar(im,ax=ax,fraction=0.045)\n",
    "    \n",
    "    if(len(dataset_type) != 0):\n",
    "        visual_title = \"Confusion Matrix for %s Set \"%dataset_type.capitalize()\n",
    "    else:\n",
    "        raise ValueError(\"Dataset set must be training or dev or test set\")\n",
    "        \n",
    "        \n",
    "    #getting the label description\n",
    "    label_desc = label_description(dataset)\n",
    "    desc = [label_desc[i] for i in range(0,10)]\n",
    "    \n",
    "    # annotating the plot\n",
    "    ax.set_title(visual_title,fontsize=24,pad = 20)    \n",
    "    ax.set_xticks(np.arange(10))\n",
    "    ax.set_yticks(np.arange(10))    \n",
    "    ax.set_xlabel(\"Predicted\", fontsize = 20)\n",
    "    ax.set_ylabel(\"Expexted\", fontsize = 20)\n",
    "    \n",
    "    ax.set_xticklabels(desc)\n",
    "    ax.set_yticklabels(desc)\n",
    "    \n",
    "    #setting horizontal axes labeling to top.\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "\n",
    "    # creating the threshold for color change in the visualization\n",
    "    thres = cm.max()//2\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            #calculating the percentage of the total image denoted by the cell\n",
    "            per = cm[i,j]/cm.sum() * 100\n",
    "            #putting up the text inside the plot cells\n",
    "            ax.text(j, i, \"%d\\n%.2f%%\"%(cm[i, j], per),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\" if cm[i,j] > thres else \"black\")\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating precision, Recall and F1-Score\n",
    "def precision(label, cm):\n",
    "    \"\"\"Returns the precision for the prediction of an individual label.\n",
    "    \n",
    "        Arguments:\n",
    "            label (int): unique labels (each class).\n",
    "            cm (numpy.ndarray): 2D confusion matrix.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **prec**: Precision for the given label.\n",
    "            \n",
    "        Example:\n",
    "            if cm = [[1 0 0 0 0 0]\n",
    "                     [0 0 1 0 0 0]\n",
    "                     [0 0 4 0 0 0]\n",
    "                     [0 1 0 1 0 0]\n",
    "                     [0 0 0 0 1 0]\n",
    "                     [0 0 0 0 0 1]]\n",
    "            >>> label = 2\n",
    "            >>> prec = precision(label, cm)\n",
    "            >>> print(prec)\n",
    "            \n",
    "            Output:\n",
    "                0.8\n",
    "    \"\"\"\n",
    "    col = cm[:, label] #selecting the True Positive and false positive values\n",
    "    prec = cm[label, label] / col.sum() #perc = TP / (TP + FP)\n",
    "    return prec\n",
    "    \n",
    "def recall(label, cm):\n",
    "    \"\"\"Returns the recall for the prediction of an individual label.\n",
    "    \n",
    "        Arguments:\n",
    "            label (int): unique labels (each class).\n",
    "            cm (numpy.ndarray): 2D confusion matrix.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **rec**: Recall for the given label.\n",
    "            \n",
    "        Example:\n",
    "            if cm = [[1 0 0 0 0 0]\n",
    "                     [0 0 1 0 0 0]\n",
    "                     [0 0 4 0 0 0]\n",
    "                     [0 1 0 1 0 0]\n",
    "                     [0 0 0 0 1 0]\n",
    "                     [0 0 0 0 0 1]]\n",
    "            >>> label = 2\n",
    "            >>> rec = recall(label, cm)\n",
    "            >>> print(rec)\n",
    "            \n",
    "            Output:\n",
    "                1.0\n",
    "    \"\"\"\n",
    "    row = cm[label, :] #selecting the True Positive and false Negative values\n",
    "    rec = cm[label, label] / row.sum() # rec = TP / (TP + FN)\n",
    "    return rec\n",
    "\n",
    "def f1_score(prec,rec):\n",
    "    \"\"\"Returns the f1-score for the prediction of an individual label.\n",
    "    \n",
    "        Arguments:\n",
    "            prec (numpy.float64): precision for a label.\n",
    "            rec (numpy.float64): recall for a label.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **f1**: f1-score for the precision and recall.\n",
    "            \n",
    "        Example:\n",
    "            >>> prec = 0.8\n",
    "            >>> rec = 1.0\n",
    "            >>> f1 = f1_score(prec,rec)\n",
    "            >>> print(f1)\n",
    "            \n",
    "            Output:\n",
    "                0.888888888888889\n",
    "    \"\"\"\n",
    "    f1 = (2 * prec * rec) / (prec + rec)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating macro precision, recall and f1-score\n",
    "def macro_precision_average(precs):\n",
    "    \"\"\"Returns the macro average of the precisions for the prediction of all the label.\n",
    "    \n",
    "        Arguments:\n",
    "            precs (list): lists of precisions of type numpy.float64.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **prec_mac_avg**: macro average of the precisions.\n",
    "            \n",
    "        Example:\n",
    "            >>> avg_precision = macro_precision_average(prec)\n",
    "    \"\"\"\n",
    "    count = len(precs)    \n",
    "    prec_mac_avg = np.sum(precs) / count\n",
    "    return prec_mac_avg\n",
    "\n",
    "def macro_recall_average(recs):\n",
    "    \"\"\"Returns the macro average of the recall for the prediction of all the label.\n",
    "    \n",
    "        Arguments:\n",
    "            recs (list): lists of recalls of type numpy.float64.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **rec_mac_avg**: macro average of the recalls.\n",
    "            \n",
    "        Example:\n",
    "            >>> avg_recall = macro_recall_average(rec)\n",
    "    \"\"\"\n",
    "    count = len(recs)\n",
    "    rec_mac_avg = np.sum(recs) / count\n",
    "    return rec_mac_avg\n",
    "\n",
    "def macro_f1_score(f1s):\n",
    "    \"\"\"Returns the macro average of the f1-score for the prediction of all the label.\n",
    "    \n",
    "        Arguments:\n",
    "            f1s (list): lists of f1-scores of type numpy.float64.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.float64: - **f1_mac_avg**: macro average of the f1-scores.\n",
    "            \n",
    "        Example:\n",
    "            >>> avg_f1 = macro_f1_score(f1)\n",
    "    \"\"\"\n",
    "    count = len(f1s)\n",
    "    f1_mac_avg = np.sum(f1s) / count\n",
    "    return f1_mac_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculating the accuracy\n",
    "def accuracy(cm):\n",
    "    \"\"\"Returns the accuracy of the prediction.\n",
    "    \n",
    "        Arguments:\n",
    "            cm (numpy.ndarray): 2D confusion matrix.\n",
    "\n",
    "        Returns:\n",
    "            numpy.float64: - **acc**: Accuracy of the prediction.\n",
    "            \n",
    "        Example:\n",
    "            if cm = [[1 0 0 0 0 0]\n",
    "                     [0 0 1 0 0 0]\n",
    "                     [0 0 4 0 0 0]\n",
    "                     [0 1 0 1 0 0]\n",
    "                     [0 0 0 0 1 0]\n",
    "                     [0 0 0 0 0 1]]\n",
    "            >>> acc = accuracy(cm)\n",
    "            \n",
    "            Outputs:\n",
    "                0.8\n",
    "    \"\"\"\n",
    "    diagonal_sum = cm.trace() # getting the total truely classified images\n",
    "    sum_of_all_elements = cm.sum() # getting the total number of images\n",
    "    acc = diagonal_sum / sum_of_all_elements \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating model metrices\n",
    "def model_metrics(cm):\n",
    "    \"\"\"Returns the metrices and macro metrices for the evaluation of the model.\n",
    "        Metrices includes:\n",
    "            Precision, Recall and F1-score\n",
    "        Macro Metrices includes:\n",
    "            Macro Precision Average, Macro Recall Average and Macro F1-score Average\n",
    "    \n",
    "        Arguments:\n",
    "            cm (numpy.ndarray): 2D confusion matrix.\n",
    "\n",
    "        Returns: tuple: Following Values\n",
    "            - **metrices** (dict): Model Metrices including list of Precision, Recall and F1-score.\n",
    "            - **macro_metrices** (dict): Model Macro metrices including Macro Precision Average, Macro Recall Average and Macro F1-score Average.\n",
    "            - **acc** (numpy.float64): Accuracy of the prediction.\n",
    "            \n",
    "        Example:\n",
    "            >>> metrics, macro_metrics, acc = model_metrics(cm)\n",
    "    \"\"\"\n",
    "    precs = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "    metrics = {}\n",
    "    macro_metrics = {}\n",
    "    # calculating precision, recall and f1-score for all the classes or labels\n",
    "    for label in range(10):\n",
    "        precs.append(precision(label, cm))\n",
    "        recs.append(recall(label, cm))\n",
    "        f1s.append(f1_score(precs[label], recs[label]))\n",
    "    \n",
    "    #calculating the macro average metrices\n",
    "    avg_precision = macro_precision_average(precs) #calculating the macro metrices\n",
    "    avg_recall = macro_recall_average(recs)\n",
    "    avg_f1 = macro_f1_score(f1s)\n",
    "    acc = accuracy(cm)\n",
    "    \n",
    "    metrics = {\"Precision\":precs,\n",
    "               \"Recall\":recs,\n",
    "               \"F1-Score\":f1s}\n",
    "    macro_metrics = {\"Precision\":avg_precision,\n",
    "                     \"Recall\":avg_recall,\n",
    "                     \"F1-Score\":avg_f1}\n",
    "    \n",
    "    return metrics, macro_metrics, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##displaying the model summary\n",
    "def metric_summary(metrics, macro_metrics, accuracy):\n",
    "    \"\"\"Displays the metric summary after evaluation.\n",
    "    \n",
    "        Arguments:\n",
    "            metrices (dict): Model Metrices including list of Precision, Recall and F1-score.\n",
    "            macro_metrices (dict): Model Macro metrices including Macro Precision Average, Macro Recall Average and Macro F1-score Average.\n",
    "            accuracy (numpy.float64): Accuracy of the prediction.\n",
    "            \n",
    "        Example:\n",
    "            >>> metric_summary(metrics, macro_metrics, acc)\n",
    "    \"\"\"\n",
    "    print(\"+===============+===============+===============+===============+\")\n",
    "    print(\"| Label \\t| Precision \\t| Recall \\t| F1 Score \\t|\")\n",
    "    print(\"+===============+===============+===============+===============+\")\n",
    "    prec = metrics[\"Precision\"]\n",
    "    rec = metrics[\"Recall\"]\n",
    "    f1 = metrics[\"F1-Score\"]\n",
    "    \n",
    "    for label in range(len(prec)):\n",
    "        print(\"| %d \\t\\t|  %.5f \\t|  %.5f \\t|  %.5f \\t|\"%(label, prec[label], rec[label], f1[label]))\n",
    "\n",
    "    print(\"+===============+===============+===============+===============+\") \n",
    "    \n",
    "    avg_precision = macro_metrics[\"Precision\"]\n",
    "    avg_recall = macro_metrics[\"Recall\"]\n",
    "    avg_f1 = macro_metrics[\"F1-Score\"]\n",
    "    acc = accuracy\n",
    "    \n",
    "    print(\"| Macro Avg \\t|  %.5f \\t|  %.5f \\t|  %.5f \\t|\"%( avg_precision, avg_recall, avg_f1))\n",
    "    print(\"+===============+===============+===============+===============+\") \n",
    "    \n",
    "    print(\"\\n Accuracy \\t\\t  %.5f\"%(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Predictions and acc-loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Training Result\n",
    "\n",
    "def visualize_training_results(train_accs, val_accs, train_loss, val_loss):\n",
    "    \"\"\"Visualize the traininig accuracy and loss, validation accuracy and loss over the training time.\n",
    "    \n",
    "        Arguments:\n",
    "            train_accs (list): training accuracies obtained in all the minibatches in all epochs\n",
    "            val_accs (list): validation accuracies obtained in all the minibatches in all epochs\n",
    "            train_loss (list): training losses obtained in all the minibatches in all epochs\n",
    "            val_loss (list): validation losses obtained in all the minibatches in all epochs\n",
    "            \n",
    "        Example:\n",
    "            >>> visualize_training_results(train_accs, val_accs, train_losses, val_losses)    \n",
    "    \"\"\"\n",
    "    \n",
    "    #creating subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols = 1,figsize=(10,15))\n",
    "    fig.subplots_adjust(wspace=.2, hspace = .5)\n",
    "    \n",
    "    #plotting the loss\n",
    "    axes[0].plot(np.squeeze(train_loss), label = 'Training Loss', color = 'blue')\n",
    "    axes[0].plot(np.squeeze(val_loss), label = 'Validation Loss', color = 'red')\n",
    "    axes[0].legend(loc='upper right') #setting up legend location to upper right corner of the plot\n",
    "    axes[0].set_title(\"Training and Validation Loss \" , fontsize = 16, pad = 10)\n",
    "    axes[0].set_xlabel(\"No. of Epochs\", fontsize = 12)\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize = 12)\n",
    "    axes[0].set_ylim(bottom = 0)  \n",
    "    axes[0].grid(color='grey', alpha = 0.5)\n",
    "    \n",
    "    #plotting the accuracy\n",
    "    axes[1].plot(np.squeeze(train_accs), label = 'Training Accuracy', color = 'blue')\n",
    "    axes[1].plot(np.squeeze(val_accs), label = 'Validation Accuracy', color = 'red')\n",
    "    axes[1].legend(loc='lower right') #setting up legend location to lower right corner of the plot\n",
    "    axes[1].set_title(\"Accuracy \" , fontsize = 16, pad = 10)\n",
    "    axes[1].set_xlabel(\"No. of Epochs\", fontsize = 12)\n",
    "    axes[1].set_ylabel(\"Accuracy\", fontsize = 12)\n",
    "    axes[1].set_ylim(top = 1)  \n",
    "    axes[1].grid(color='grey', alpha = 0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Prediction\n",
    "def visualize_prediction(x_orig, y_orig, prediction, dataset_type, dataset = \"mnist\"):\n",
    "    \"\"\"Displays 10 random images along with their true and predicted labels. \n",
    "        Both initial prediction and second guess are displayed.\n",
    "    \n",
    "        Arguments:\n",
    "            x_orig (numpy.ndarray): original input data.\n",
    "            y_orig (numpy.ndarray): original output labels.\n",
    "            prediction (numpy.ndarray): predictions obtained after training the model.\n",
    "            dataset_type (str): Type of dataset. May be training, dev  or test.\n",
    "            dataset (str): Dataset used to train the model. Default to 'mnist'\n",
    "            \n",
    "        Example:\n",
    "            >>> visualize_prediction(x_orig, y_orig.T, prediction, dataset_type = \"training\")\n",
    "    \"\"\"\n",
    "    if(len(dataset_type) != 0):\n",
    "        visual_title = \"Sample %s Data Set \"%dataset_type.capitalize()\n",
    "    else:\n",
    "        raise ValueError(\"Dataset set must be training or dev or test set\")\n",
    "    \n",
    "    #getting the random index of 8 images to plot\n",
    "    index = np.random.randint(0,1000,8)\n",
    "    \n",
    "    #getting the label description\n",
    "    label_desc = label_description(dataset)\n",
    "    \n",
    "    #plotting the images along with the predictions\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4,figsize=(16,8))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    fig.suptitle(visual_title)\n",
    "\n",
    "    first_lbl, first_prob = prediction[\"First Prediction\"]\n",
    "    sec_lbl, sec_prob = prediction[\"Second Prediction\"]\n",
    "\n",
    "    for ax,i in zip(axes.flatten(),index):\n",
    "        ax.imshow(x_orig[i].squeeze(),interpolation='nearest', cmap='Greys')\n",
    "        ax.set(title = \"True Label: %d | %s\"%(y_orig[0,i], label_desc[y_orig[0,i]] ))\n",
    "        ax.set(xlabel= \"Prediction: %d | With Prob: %.4f \\n2nd Guess: %d | With Prob: %.4f\"%(first_lbl[0,i], first_prob[0,i], sec_lbl[0,i], sec_prob[0,i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Mislabeled Data\n",
    "def visualize_mislabelled_images(x_orig,y_orig,prediction,dataset_type, dataset = \"mnist\"):\n",
    "    \"\"\"Displays 10 wrongly predicted images along with their true and predicted labels. \n",
    "        Both initial prediction and second guess are displayed.\n",
    "    \n",
    "        Arguments:\n",
    "            x_orig (numpy.ndarray): original input data.\n",
    "            y_orig (numpy.ndarray): original output labels.\n",
    "            prediction (numpy.ndarray): predictions obtained after training the model.\n",
    "            dataset_type (str): Type of dataset. May be training, dev  or test.\n",
    "            dataset (str): Dataset used to train the model. Default to 'mnist'\n",
    "            \n",
    "        Example:\n",
    "            >>> visualize_mislabelled_images(x_orig, y_orig.T, prediction, dataset_type = \"training\")\n",
    "    \"\"\"\n",
    "    \n",
    "    first_lbl, first_prob = prediction[\"First Prediction\"]\n",
    "    sec_lbl, sec_prob = prediction[\"Second Prediction\"]\n",
    "    \n",
    "    true_prediction = np.equal(first_lbl,y_orig)\n",
    "    mislabelled_indices = np.asarray(np.where(true_prediction == False))\n",
    "    print(\"Total Mislabelled Images: \"+str(len(mislabelled_indices[0])))\n",
    "    \n",
    "    if(len(dataset_type) != 0):\n",
    "        visual_title = \"Sample Mislabelled %s Set Images \"%dataset_type.capitalize()\n",
    "    else:\n",
    "        raise ValueError(\"Dataset set must be training or dev or test set\")\n",
    "    \n",
    "    #getting the label description\n",
    "    label_desc = label_description(dataset)     \n",
    "    \n",
    "    #plotting the mislabelled images along with the predictions\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=5,figsize=(16,8))\n",
    "    fig.subplots_adjust(hspace=1)\n",
    "    fig.suptitle(visual_title)\n",
    "\n",
    "    for ax,i in zip(axes.flatten(),mislabelled_indices[1]):\n",
    "        ax.imshow(x_orig[i].squeeze(),interpolation='nearest', cmap = \"Greys\")\n",
    "        ax.set(title = \"True Label: %d | %s\"%(y_orig[0,i], label_desc[y_orig[0,i]] ))\n",
    "        ax.set(xlabel= \"Prediction: %d | With Prob: %.4f \\n2nd Guess: %d | With Prob: %.4f\"%(first_lbl[0,i], first_prob[0,i], sec_lbl[0,i], sec_prob[0,i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving Model\n",
    "def save_model(file_name, model):\n",
    "    \"\"\"Saves the parameters of the trained model into a pickle file.\n",
    "    \n",
    "        Arguments:\n",
    "            file_name (str): name of the file to be saved.\n",
    "            model (dict): trained model to be saved in the file. Consists of Parameters and activations \n",
    "            \n",
    "        Example:\n",
    "            >>> save_model(file_name = path + fname, model)\n",
    "    \"\"\"\n",
    "    with open(file_name ,'wb') as output_file:\n",
    "        pickle.dump(model,output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Model\n",
    "def load_model(file_name):\n",
    "    \"\"\"Load the saved model from a pickle file\n",
    "    \n",
    "        Arguments:\n",
    "            file_name (str): name of the file to be loaded from\n",
    "        \n",
    "        Returns:\n",
    "            model (dict): trained model to be saved in the file. Consists of Parameters and activations \n",
    "            \n",
    "        Example:\n",
    "            >>> model = load_model(file_name = path + fname)\n",
    "    \"\"\"\n",
    "    try: \n",
    "        with open(file_name ,'rb') as input_file:\n",
    "            model = pickle.load(input_file)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except(OSError, IOError) as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(X,Y,hidden_layers):\n",
    "    \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "            \n",
    "            \n",
    "        Example:\n",
    "            Here, shape of x = (784,m)\n",
    "                  shape of y = (10,m)\n",
    "            >>> layers_dim = init_layers(x, y, hidden_layers = [32,16])\n",
    "            >>> print(layers_dim)\n",
    "            \n",
    "            Outputs:\n",
    "                [784, 32, 16, 10]\n",
    "    \"\"\"\n",
    "    input_nodes = X.shape[0]\n",
    "    output_nodes = Y.shape[0]\n",
    "    \n",
    "    layers_dim = [input_nodes]\n",
    "    \n",
    "    for i in hidden_layers:\n",
    "        layers_dim.append(i)\n",
    "    \n",
    "    layers_dim.append(output_nodes)\n",
    "    \n",
    "    return layers_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(layers_dim, initialization = \"random\"):\n",
    "    \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "            \n",
    "            \n",
    "        Example:\n",
    "            Here, layers_dim = [784, 32, 16, 10]\n",
    "            >>> parameters = init_parameters(layers_dim, initialization = \"random\")\n",
    "            >>> print(\"Layer\\tWeight\\t\\tBias\")\n",
    "            >>> print(\"================================\")\n",
    "            >>> for l in range(1,len(layers_dim)):\n",
    "            ...     print(str(l) +\"\\t\" + str(parameters['W'+str(l)].shape) +\"\\t\"+ str(parameters['b'+str(l)].shape))\n",
    "\n",
    "            \n",
    "            Outputs:\n",
    "                Layer    Weight         Bias\n",
    "                ================================\n",
    "                1        (32, 784)      (32, 1)\n",
    "                2        (16, 32)       (16, 1)\n",
    "                3        (10, 16)       (10, 1)\n",
    "    \"\"\"\n",
    "    L = len(layers_dim)\n",
    "    params = {}\n",
    "        \n",
    "    for l in range(1,L):\n",
    "        #initializing Weights\n",
    "        if initialization == \"he\":\n",
    "            # he-initialization\n",
    "            params['W' + str(l)] = np.random.randn(layers_dim[l],layers_dim[l-1]) * np.sqrt(np.divide(2,layers_dim[l-1])) \n",
    "        elif initialization == \"random\":\n",
    "            # random initialization scaled by 0.01\n",
    "            params['W' + str(l)] = np.random.randn(layers_dim[l],layers_dim[l-1]) * 0.01 \n",
    "        else:\n",
    "             raise ValueError(\"Initialization must be 'random' or 'he'\")\n",
    "        \n",
    "        #initializing biases\n",
    "        params['b' + str(l)] = np.zeros((layers_dim[l],1))\n",
    "     \n",
    "        assert(params['W' + str(l)].shape == (layers_dim[l],layers_dim[l-1])), \"Dimention of W mismatched in init_params function\"\n",
    "        assert(params['b' + str(l)].shape == (layers_dim[l],1)), \"Dimention of b mismatched in init_params function\"\n",
    "   \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hyperParams(alpha, num_epoch, minibatch_size, lambd = 0, keep_probs = []):\n",
    "    \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "            \n",
    "            \n",
    "        Example:\n",
    "            >>> hyperParams = init_hyperParams(alpha = 0.0001, num_epoch = 10, minibatch_size = 1024,lambd = 0.7,keep_probs = [0.8,0.8])\n",
    "    \"\"\"\n",
    "    hyperParams = {'learning_rate':alpha,\n",
    "                   'num_epoch':num_epoch,\n",
    "                   'mini_batch_size':minibatch_size,\n",
    "                   'lambda':lambd,\n",
    "                   'keep_probs':keep_probs,\n",
    "                   'beta1':0.9,\n",
    "                   'beta2':0.999,\n",
    "                   'epsilon':1e-8\n",
    "                  }\n",
    "    \n",
    "    return hyperParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Sum for individual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_sum(A_prev,W,b):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> A = np.random.randn(3,2)\n",
    "            >>> W = np.random.randn(1,3)\n",
    "            >>> b = np.random.randn(1,1)\n",
    "            >>> Z, c = forward_sum(A,W,b)\n",
    "            >>> print(\"Z = \"+ str(Z))\n",
    "            \n",
    "            Output:\n",
    "                Z = [[ 3.26295337 -1.23429987]]\n",
    "        \n",
    "    \"\"\"\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    Z = np.dot(W,A_prev) + b\n",
    "    \n",
    "    cache = (A_prev,W,b)\n",
    "    \n",
    "    assert (Z.shape == (W.shape[0], m)), \"Dimention of Z mismatched in forward_prop function\"\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Activation for individual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_activation(A_prev,W,b,activation):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> A_prev = np.random.randn(3,2)\n",
    "            >>> W = np.random.randn(1,3)\n",
    "            >>> b = np.random.randn(1,1)\n",
    "\n",
    "            >>> A,c = forward_activation(A_prev,W,b,activation = 'relu')\n",
    "            >>> print(\"A with Relu = \" + str(A))\n",
    "\n",
    "            >>> A,c = forward_activation(A_prev,W,b,activation = 'softmax')\n",
    "            >>> print(\"A with Softmax = \" + str(A))\n",
    "            \n",
    "            Output:\n",
    "                A with Relu = [[3.26295337 0.        ]]\n",
    "                A with Softmax = [[1. 1.]]\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        Z, sum_cache = forward_sum(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    elif activation == 'softmax':\n",
    "        Z, sum_cache = forward_sum(A_prev,W,b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "#         Z, sum_cache = forward_sum(A_prev,W,b)\n",
    "#         A, activation_cache = tanh(Z)\n",
    "        pass\n",
    "    \n",
    "    cache = (sum_cache,activation_cache)\n",
    "    \n",
    "    assert(A.shape == Z.shape), \"Dimention of A mismatched in forward_activation function\"\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout for individual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_dropout(A,keep_probs):\n",
    "     #implementing dropout\n",
    "    D = np.random.rand(A.shape[0],A.shape[1])\n",
    "    D = (D < keep_probs).astype(int)\n",
    "    A = np.multiply(A,D)\n",
    "    A = np.divide(A,keep_probs)\n",
    "    \n",
    "    dropout_mask = D\n",
    "    \n",
    "    assert (dropout_mask.shape == A.shape), \"Dimention of dropout_mask mismatched in forward_dropout function\"\n",
    "    return A,dropout_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Prop for L Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, parameters, keep_probs = [], regularizer = None):\n",
    "    \"\"\"\n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> X = np.random.randn(3,2)\n",
    "            >>> W1 = np.random.randn(3,3)\n",
    "            >>> b1 = np.random.randn(3,1)\n",
    "            >>> W2 = np.random.randn(2,3)\n",
    "            >>> b2 = np.random.randn(2,1)\n",
    "            >>> parameters = {\"W1\": W1,\n",
    "                              \"b1\": b1,\n",
    "                              \"W2\": W2,\n",
    "                              \"b2\": b2}\n",
    "            >>> AL, caches, _ = forward_prop(X, parameters)\n",
    "            >>> print(\"AL without dropout = \" + str(AL))\n",
    "\n",
    "            >>> AL, caches, _ = forward_prop(X, parameters,keep_probs = [0.9], regularizer = \"dropout\")\n",
    "            >>> print(\"\\nAL with dropout = \" + str(AL))\n",
    "\n",
    "            >>> print(\"\\nLength of caches list = \" + str(len(caches)))\n",
    "            \n",
    "            Output:\n",
    "                AL without dropout = [[0.25442549 0.64096177]\n",
    "                 [0.74557451 0.35903823]]\n",
    "\n",
    "                AL with dropout = [[0.20251119 0.61487938]\n",
    "                 [0.79748881 0.38512062]]\n",
    "\n",
    "                Length of caches list = 2\n",
    "    \n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    num_class = parameters[\"W\"+str(L)].shape[0]\n",
    "    \n",
    "    dropout_masks = []\n",
    "\n",
    "    # len(keep_probs) == L-1: no dropouts in the Output layer, no dropout at all for prediction\n",
    "    if regularizer == \"dropout\":\n",
    "        assert(len(keep_probs) == L-1 ) \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = forward_activation(A_prev,parameters['W' + str(l)],parameters['b' + str(l)], activation='relu')\n",
    "        caches.append(cache)\n",
    "        if regularizer == \"dropout\":\n",
    "            A , dropout_mask = forward_dropout(A,keep_probs[l-1])\n",
    "            dropout_masks.append(dropout_mask)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    AL, cache = forward_activation(A, parameters['W' + str(L)], parameters['b' + str(L)], activation='softmax')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (num_class,X.shape[1])), \"Dimention of AL mismatched in forward_prop function\"\n",
    "    \n",
    "    return AL,caches,dropout_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_cost(AL, Y, caches, lambd = 0, regularizer = None, from_logits = False ):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        Example:\n",
    "            >>> AL = np.array([[4.21200131e-01, 1.55876995e-04],\n",
    "                           [6.91917292e-02, 1.18118501e-05],\n",
    "                           [5.09608140e-01, 9.99832311e-01]])\n",
    "            >>> cost = softmax_cross_entropy_cost(AL, Y, caches)\n",
    "            >>> print(\"Cost without l2 = \" + str(cost))\n",
    "\n",
    "            >>> cost = softmax_cross_entropy_cost(AL, Y, caches, lambd = 0.7, regularizer = 'l2')\n",
    "            >>> print(\"Cost with l2 = \" + str(cost))\n",
    "            \n",
    "            Output:\n",
    "                Cost without l2 = 0.6742809046007259\n",
    "                Cost with l2 = 8.875542970361\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(caches)\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "     #cost computation from logit\n",
    "    #ref link : https://www.d2l.ai/chapter_linear-networks/softmax-regression-concise.html\n",
    "    if from_logits == True:\n",
    "        z = caches[-1][-1] #retriving the logit(activation cache) of the last layer from the caches\n",
    "        s\n",
    "        z = z - np.max(z,axis = 0) #calculating negative z for avoiding numerical overflow in exp computation\n",
    "        logit_log =  z - np.log(np.sum(np.exp(z),axis = 0)) #calculating the log of the softmax to feed into cost\n",
    "        cost = -(1./m) * np.sum(np.sum(np.multiply(Y,logit_log), axis = 0,keepdims=True))\n",
    "        \n",
    "    else:\n",
    "        cost = -(1./m) * np.sum(np.sum(np.multiply(Y,np.log(AL + 1e-8)), axis = 0,keepdims=True))# add very small number 1e-8 to avoid log(0)\n",
    "ss\n",
    "    if regularizer == \"l2\":\n",
    "        norm = 0\n",
    "        for l in range(L):\n",
    "            current_cache = caches[l]\n",
    "            sum_cache, _ = current_cache\n",
    "            _,W,_ = sum_cache\n",
    "            norm += np.sum(np.square(W))\n",
    "\n",
    "        L2_cost = (lambd/(2*m)) * norm \n",
    "        cost = cost + L2_cost\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    cost = np.squeeze(cost)      # Making sure your cost's shape is not returned as ndarray\n",
    "    \n",
    "    assert(cost.shape == ()),\"Dimention of cost mismatched in softmax_cross_entropy_cost function\"\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Gradients for individual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_grad(dZ, cache, lambd, regularizer):\n",
    "    \"\"\"\n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> dZ = np.random.randn(3,4)\n",
    "            >>> A = np.random.randn(5,4)\n",
    "            >>> W = np.random.randn(3,5)\n",
    "            >>> b = np.random.randn(3,1)\n",
    "            >>> cache = (A, W, b)\n",
    "\n",
    "            >>> dA_prev, dW, db = backward_grad(dZ, cache, lambd=0, regularizer=None)\n",
    "            >>> print(\"Without L2 Regularization\")\n",
    "            >>> print (\"dA_prev = \"+ str(dA_prev))\n",
    "            >>> print (\"dW = \" + str(dW))\n",
    "            >>> print (\"db = \" + str(db))\n",
    "\n",
    "            >>> l2_dA_prev, l2_dW, l2_db = backward_grad(dZ, cache, lambd = 0.9, regularizer = 'l2')\n",
    "            >>> print(\"\\nWith L2 Regularization\")\n",
    "            >>> print (\"dA_prev = \"+ str(l2_dA_prev))\n",
    "            >>> print (\"dW = \" + str(l2_dW))\n",
    "            >>> print (\"db = \" + str(l2_db))\n",
    "            \n",
    "            Output:\n",
    "                Without L2 Regularization\n",
    "                dA_prev = [[-1.15171336  0.06718465 -0.3204696   2.09812712]\n",
    "                           [ 0.60345879 -3.72508701  5.81700741 -3.84326836]\n",
    "                           [-0.4319552  -1.30987417  1.72354705  0.05070578]\n",
    "                           [-0.38981415  0.60811244 -1.25938424  1.47191593]\n",
    "                           [-2.52214926  2.67882552 -0.67947465  1.48119548]]\n",
    "                dW = [[ 0.07313866 -0.0976715  -0.87585828  0.73763362  0.00785716]\n",
    "                      [ 0.85508818  0.37530413 -0.59912655  0.71278189 -0.58931808]\n",
    "                      [ 0.97913304 -0.24376494 -0.08839671  0.55151192 -0.10290907]]\n",
    "                db = [[-0.14713786]\n",
    "                      [-0.11313155]\n",
    "                      [-0.13209101]]\n",
    "\n",
    "                With L2 Regularization\n",
    "                dA_prev = [[-1.15171336  0.06718465 -0.3204696   2.09812712]\n",
    "                           [ 0.60345879 -3.72508701  5.81700741 -3.84326836]\n",
    "                           [-0.4319552  -1.30987417  1.72354705  0.05070578]\n",
    "                           [-0.38981415  0.60811244 -1.25938424  1.47191593]\n",
    "                           [-2.52214926  2.67882552 -0.67947465  1.48119548]]\n",
    "                dW = [[-0.0814752  -0.28784277 -1.02688866  0.73478408 -0.24353767]\n",
    "                      [ 0.90783172  0.74875962 -0.43216662  0.6696189  -0.78903459]\n",
    "                      [ 0.81102242  0.13703735 -0.07696496  0.4081879  -0.05995309]]\n",
    "                db = [[-0.14713786]\n",
    "                      [-0.11313155]\n",
    "                      [-0.13209101]]\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if regularizer == \"l2\":\n",
    "        dW = (1/m) * np.dot(dZ,A_prev.T) + np.multiply(np.divide(lambd,m),W )\n",
    "    else:\n",
    "        dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "\n",
    "    db = (1/m) * np.sum(dZ, axis = 1, keepdims=True )\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    \n",
    "    assert (dW.shape == W.shape), \"Dimention of dW mismatched in backward_grad function\"\n",
    "    assert (db.shape == b.shape), \"Dimention of db mismatched in backward_grad function\"\n",
    "    assert (dA_prev.shape == A_prev.shape), \"Dimention of dA_prev mismatched in backward_grad function\"\n",
    "    \n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Backward Activation for individual layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_activation(dA, cache, lambd ,regularizer, activation):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "        >>> np.random.seed(2)\n",
    "        >>> dA = np.random.randn(1,2)\n",
    "        >>> A = np.random.randn(3,2)\n",
    "        >>> W = np.random.randn(1,3)\n",
    "        >>> b = np.random.randn(1,1)\n",
    "        >>> Z = np.random.randn(1,2)\n",
    "        >>> sum_cache = (A, W, b)\n",
    "        >>> activation_cache = Z\n",
    "        >>> cache = (sum_cache, activation_cache)\n",
    "\n",
    "        >>> dA_prev, dW, db = backward_activation(dA, cache, lambd = 0 ,regularizer = None, activation = \"relu\")\n",
    "        >>> print(\"With Relu\")\n",
    "        >>> print (\"dA_prev = \"+ str(dA_prev))\n",
    "        >>> print (\"dW = \" + str(dW))\n",
    "        >>> print (\"db = \" + str(db))\n",
    "\n",
    "        >>> dA_prev, dW, db = backward_activation(dA, cache, lambd = 0 ,regularizer = None, activation = \"softmax\")\n",
    "        >>> print(\"\\nWith Softmax\")\n",
    "        >>> print (\"dA_prev = \"+ str(dA_prev))\n",
    "        >>> print (\"dW = \" + str(dW))\n",
    "        >>> print (\"db = \" + str(db))\n",
    "        \n",
    "        Output: \n",
    "            With Relu\n",
    "            dA_prev = [[ 0.44090989 -0.        ]\n",
    "                       [ 0.37883606 -0.        ]\n",
    "                       [-0.2298228   0.        ]]\n",
    "            dW = [[ 0.44513824  0.37371418 -0.10478989]]\n",
    "            db = [[-0.20837892]]\n",
    "\n",
    "            With Softmax\n",
    "            dA_prev = [[ 0.44090989  0.05952761]\n",
    "                       [ 0.37883606  0.05114697]\n",
    "                       [-0.2298228  -0.03102857]]\n",
    "            dW = [[ 0.39899183  0.3973954  -0.06975568]]\n",
    "            db = [[-0.23651234]]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    sum_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_grad(dA,activation_cache)\n",
    "        dA_prev, dW, db = backward_grad(dZ, sum_cache, lambd, regularizer = regularizer)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        dZ = dA\n",
    "        dA_prev, dW, db = backward_grad(dZ, sum_cache, lambd, regularizer = regularizer)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        pass\n",
    "#         dZ = tanh_grad(dA,activation_cache)\n",
    "#         dA_prev, dW, db = backward_grad(dZ, sum_cache, lambd, regularizer = regularizer)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Backward Propagation for L layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_dropout(dA_prev_temp, D, keep_prob):\n",
    "    dA_prev = np.multiply(dA_prev_temp,D)\n",
    "    dA_prev = np.divide(dA_prev,keep_prob)\n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(AL, Y, caches, dropout_masks = [], keep_probs = [], lambd = 0, regularizer = None):\n",
    "    \"\"\"\n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(3)\n",
    "            >>> AL = np.random.randn(1, 2)\n",
    "            >>> Y = np.array([[1, 0]])\n",
    "\n",
    "            >>> A1 = np.random.randn(4,2)\n",
    "            >>> W1 = np.random.randn(3,4)\n",
    "            >>> b1 = np.random.randn(3,1)\n",
    "            >>> Z1 = np.random.randn(3,2)\n",
    "            >>> cache_activation_1 = ((A1, W1, b1), Z1)\n",
    "\n",
    "            >>> A2 = np.random.randn(3,2)\n",
    "            >>> W2 = np.random.randn(1,3)\n",
    "            >>> b2 = np.random.randn(1,1)\n",
    "            >>> Z2 = np.random.randn(1,2)\n",
    "            >>> cache_activation_2 = ((A2, W2, b2), Z2)\n",
    "\n",
    "            >>> caches = (cache_activation_1, cache_activation_2)\n",
    "\n",
    "            >>> grads = backward_prop(AL, Y, caches)\n",
    "            >>> for key,value in grads.items():\n",
    "            ...     print(str(key)+\" : \"+str(value))\n",
    "            \n",
    "            Output:\n",
    "                dA1 : [[-0.80745758 -0.44693186]\n",
    "                       [ 0.88640102  0.49062745]\n",
    "                       [-0.10403132 -0.05758186]]\n",
    "                dW2 : [[ 0.50767257 -0.42243102 -1.15550109]]\n",
    "                db2 : [[0.61256916]]\n",
    "                dA0 : [[ 0.          0.53064147]\n",
    "                       [ 0.         -0.3319644 ]\n",
    "                       [ 0.         -0.32565192]\n",
    "                       [ 0.         -0.75222096]]\n",
    "                dW1 : [[0.41642713 0.07927654 0.14011329 0.10664197]\n",
    "                       [0.         0.         0.         0.        ]\n",
    "                       [0.05365169 0.01021384 0.01805193 0.01373955]]\n",
    "                db1 : [[-0.22346593]\n",
    "                       [ 0.        ]\n",
    "                       [-0.02879093]]\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    dA = np.subtract(AL,Y)\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = backward_activation(dA, current_cache,lambd = lambd, regularizer = regularizer, activation = 'softmax')\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        \n",
    "        if regularizer == \"dropout\":\n",
    "            #implementing dropout\n",
    "            D = dropout_masks[l]\n",
    "            dA_prev_temp = backward_dropout(grads[\"dA\" + str(l + 1)], D, keep_probs[l])\n",
    "            dA_prev, dW_temp, db_temp = backward_activation(dA_prev_temp, current_cache, lambd = lambd, regularizer = regularizer, activation = 'relu')\n",
    "        else:\n",
    "            dA_prev, dW_temp, db_temp = backward_activation(grads[\"dA\" + str(l + 1)], current_cache, lambd = lambd, regularizer = regularizer, activation = 'relu')\n",
    "            \n",
    "        \n",
    "        grads[\"dA\" + str(l)] = dA_prev\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize adam\n",
    "\n",
    "def initialize_adam(parameters) :\n",
    "   \n",
    "    L = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate, optimizer = \"bgd\", beta1 = 0, beta2 = 0,  epsilon = 0, v = {}, s = {}, t = 0):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(2)\n",
    "            >>> W1 = np.random.randn(3,4)\n",
    "            >>> b1 = np.random.randn(3,1)\n",
    "            >>> W2 = np.random.randn(1,3)\n",
    "            >>> b2 = np.random.randn(1,1)\n",
    "            >>> parameters = {\"W1\": W1,\n",
    "                          \"b1\": b1,\n",
    "                          \"W2\": W2,\n",
    "                          \"b2\": b2}\n",
    "            >>> np.random.seed(3)\n",
    "            >>> dW1 = np.random.randn(3,4)\n",
    "            >>> db1 = np.random.randn(3,1)\n",
    "            >>> dW2 = np.random.randn(1,3)\n",
    "            >>> db2 = np.random.randn(1,1)\n",
    "            >>> grads = {\"dW1\": dW1,\n",
    "                     \"db1\": db1,\n",
    "                     \"dW2\": dW2,\n",
    "                     \"db2\": db2}\n",
    "\n",
    "            >>> parameters,_,_ = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "            >>> print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "            >>> print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "            >>> print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "            >>> print (\"b2 = \"+ str(parameters[\"b2\"]))\n",
    "            \n",
    "            Output:\n",
    "                W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
    "                      [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
    "                      [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
    "                b1 = [[-0.04659241]\n",
    "                      [-1.28888275]\n",
    "                      [ 0.53405496]]\n",
    "                W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
    "                b2 = [[-0.84610769]]\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2           \n",
    "    v_corrected = {}                         \n",
    "    s_corrected = {}                       \n",
    "    \n",
    "    for l in range(L):\n",
    "        if optimizer == 'adam':\n",
    "            # Moving average of the gradients.\n",
    "            v[\"dW\" + str(l+1)] = np.add(beta1 * v[\"dW\" + str(l+1)], (1 - beta1) * grads[\"dW\" + str(l+1)])\n",
    "            v[\"db\" + str(l+1)] = np.add(beta1 * v[\"db\" + str(l+1)], (1 - beta1) * grads[\"db\" + str(l+1)])\n",
    "\n",
    "            # Compute bias-corrected first moment estimate.\n",
    "            v_corrected[\"dW\" + str(l+1)] = np.divide(v[\"dW\" + str(l+1)], (1 - np.power(beta1,t)))\n",
    "            v_corrected[\"db\" + str(l+1)] = np.divide(v[\"db\" + str(l+1)], (1 - np.power(beta1,t)))\n",
    "\n",
    "            # Moving average of the squared gradients. \n",
    "            s[\"dW\" + str(l+1)] = np.add(beta2 * s[\"dW\" + str(l+1)], (1 - beta2) * np.square(grads[\"dW\" + str(l+1)]))\n",
    "            s[\"db\" + str(l+1)] = np.add(beta2 * s[\"db\" + str(l+1)], (1 - beta2) * np.square(grads[\"db\" + str(l+1)]))\n",
    "\n",
    "            # Compute bias-corrected second raw moment estimate. \n",
    "            s_corrected[\"dW\" + str(l+1)] = np.divide(s[\"dW\" + str(l+1)], (1 - np.power(beta2,t)))\n",
    "            s_corrected[\"db\" + str(l+1)] = np.divide(s[\"db\" + str(l+1)], (1 - np.power(beta2,t)))\n",
    "\n",
    "            # Update parameters. \n",
    "            parameters[\"W\" + str(l+1)] = np.subtract(parameters[\"W\" + str(l+1)],  learning_rate * np.divide(v_corrected[\"dW\" + str(l+1)], np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon))\n",
    "            parameters[\"b\" + str(l+1)] = np.subtract(parameters[\"b\" + str(l+1)],  learning_rate * np.divide(v_corrected[\"db\" + str(l+1)], np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon))\n",
    "        else:\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * grads[\"dW\" + str(l+1)])\n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * grads[\"db\" + str(l+1)])\n",
    "            \n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model using acc and loss\n",
    "def evaluate(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    \n",
    "        Example:\n",
    "            >>> np.random.seed(1)\n",
    "            >>> X = np.random.randn(3,2)\n",
    "            >>> Y = np.array([[1, 0, 0],[0,1,1]]).reshape(3,2)\n",
    "            >>> W1 = np.random.randn(5,3)\n",
    "            >>> b1 = np.random.randn(5,1)\n",
    "            >>> W2 = np.random.randn(3,5)\n",
    "            >>> b2 = np.random.randn(3,1)\n",
    "            >>> parameters = {\"W1\": W1,\n",
    "            ...               \"b1\": b1,\n",
    "            ...               \"W2\": W2,\n",
    "            ...               \"b2\": b2}\n",
    "            >>> acc, loss = evaluate(X, Y, parameters)\n",
    "            >>> print(\"acc = %f | cost = %f\"%(acc,loss))\n",
    "            \n",
    "            Output:\n",
    "                acc = 0.500000 | cost = 0.769464\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # predicting output using fordward propogation \n",
    "    probas, caches, _ = forward_prop(X, parameters)\n",
    "    #computing loss\n",
    "    loss = softmax_cross_entropy_cost(probas, Y, caches) \n",
    "    \n",
    "    #deriving the predictrueted labels\n",
    "    true_labels = np.argmax(Y,axis=0).reshape(1,m)\n",
    "    #deriving the predicted labels\n",
    "    predicted_labels = np.argmax(probas,axis=0).reshape(1,m)\n",
    "    \n",
    "    #identifing correctly predicted labels\n",
    "    correct_prediction = np.equal(predicted_labels,true_labels)\n",
    "    \n",
    "    #computing accuracy\n",
    "    num_correct_prediction = np.sum(correct_prediction)\n",
    "    accuracy = (num_correct_prediction/m)\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
